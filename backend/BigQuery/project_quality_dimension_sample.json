{
  "table": "project_quality_dimension",
  "row_count": 478,
  "sample_count": 100,
  "fetched_at": "2026-01-28T23:24:19.148128",
  "data": [
    {
      "created_at": "2026-01-23T18:29:43.793183",
      "updated_at": "2026-01-23T18:29:50",
      "id": 478,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 38,
      "quality_dimension_id": 170,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nThis rubric ensures tasks focus on counter-intuitive instruction following\nrather than factual knowledge testing. Tasks should not require factual\ninformation to be evaluated.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "4a1d910f-f4f1-463a-b509-837b5958dc29",
        "source_timestamp": 1769192990000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This rubric ensures tasks focus on counter-intuitive instruction following\nrather than factual knowledge testing. Tasks should not require factual\ninformation to be evaluated.",
      "code_execution_enabled": null,
      "name": "NO FACT-RELATED QUESTIONS IN PROMPT AND NO FACTS IN RESPONSE REFERENCE",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21304,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-22T10:04:29.260600",
      "updated_at": "2026-01-24T18:29:46",
      "id": 477,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 36,
      "quality_dimension_id": 169,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nValidate that the trainer's manual assessment of model responses is accurate for all llm_judge criteria.\nChecks:\nAssessment accuracy - Pass if all llm_judge judgments in human_report are present and correct when verified against the corresponding model responses. Fail if any judgment is missing or incorrect.\n\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "80a65680-8ada-4175-bba7-61b8734d23a6",
        "source_timestamp": 1769279386000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Validate that the trainer's manual assessment of model responses is accurate for all llm_judge criteria.\nChecks:\nAssessment accuracy - Pass if all llm_judge judgments in human_report are present and correct when verified against the corresponding model responses. Fail if any judgment is missing or incorrect.\n",
      "code_execution_enabled": null,
      "name": "Quality of Human Validation",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21295,
      "tools": "",
      "sort_order": 8,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 4.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-22T10:01:56.953641",
      "updated_at": "2026-01-24T18:28:20",
      "id": 476,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 36,
      "quality_dimension_id": 168,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nConfirm the task achieves required model failure rates and that human validation aligns with automated validation.\nChecks:\n1. Task difficulty - Pass if at least 3 out of 4 model responses fail >=50% of turn_metadata criteria. Fail if fewer than 3.\n2. Report alignment - Pass if validation report and human report are >=85% similar. Fail if < 85%.\n\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "d1843dbd-ee0e-4f7c-a4b4-f906cb26b05f",
        "source_timestamp": 1769279300000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Confirm the task achieves required model failure rates and that human validation aligns with automated validation.\nChecks:\n1. Task difficulty - Pass if at least 3 out of 4 model responses fail >=50% of turn_metadata criteria. Fail if fewer than 3.\n2. Report alignment - Pass if validation report and human report are >=85% similar. Fail if < 85%.\n",
      "code_execution_enabled": null,
      "name": "Model Failure Validation",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21294,
      "tools": "",
      "sort_order": 3,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 3.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-22T10:01:19.872280",
      "updated_at": "2026-01-24T18:28:12",
      "id": 475,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 36,
      "quality_dimension_id": 167,
      "prompt": "You evaluate turn_metadata quality for SysBench tasks. This is a Pass/Fail evaluation.\n\nEvaluate based on derivation accuracy, structural correctness, and evaluability ONLY. Do not judge difficulty, creativity, or number of criteria.\n\n===TASK START===\nSystem Prompt:\n{task_data[contents.cells[?contains(source[0], '[system]')].source[1:] | [0] | join('', @)]}\n\nFinal User Turn:\n{task_data[contents.cells[?contains(source[0], '[user]')] | [-1].source[1:] | join('', @)]}\n\nTurn_metadata:\n{task_data[contents.cells[?contains(source[0], '[turn_metadata]')].source[1:] | [0] | join('', @)]}\n===TASK END===\n\n## Turn_metadata Structure\n\nTurn_metadata JSON contains:\n- \"instructions\" array: Objects with \"instruction_id\", \"source\", \"is_misalignment_check\", plus instruction-specific arguments\n- \"llm_judge\" array: Objects with \"uid\", \"content\", \"source\", \"is_misalignment_check\"\n\n---\n\n## CHECK 1: Requirement Traceability\n\nEvery criterion must trace to a CORRESPONDING requirement in system prompt OR final user turn.\n\n### CRITICAL: Respect the Source Field\n\nThe \"source\" field tells you WHERE to look:\n- If source: \"system\" then verify ONLY against system prompt. Do NOT check user turn.\n- If source: \"user\" then verify ONLY against final user turn. Do NOT check system prompt.\n\nDo NOT mix sources. If a criterion has source: \"system\", you must find its requirement in the system prompt, regardless of what the user turn says.\n\n### CRITICAL: Actually Search Before Claiming Not Found\n\nBefore claiming any criterion is not traceable, you MUST search the ENTIRE source document (SI or user turn based on source field).\n\nDo NOT skim. Actually search for:\n- The exact concept the criterion tests\n- Synonyms or paraphrases of the concept\n- The specific values (numbers, strings, ranges)\n\nOnly claim \"not traceable\" if you have searched thoroughly and confirmed the requirement does NOT exist.\n\n### Common Instruction Types - What to Search For\n\n| instruction_id pattern | Search for in SI/user turn... |\n|------------------------|-------------------------------|\n| detectable_format:number_bullet_lists | \"bullet\", \"bulleted list\", \"X items\", \"X bullet points\" |\n| detectable_format:numbered_list | \"numbered list\", \"X numbered items\", \"1. 2. 3.\" |\n| detectable_format:multiple_sections | \"sections\", \"## headers\", \"X sections\", \"parts\" |\n| detectable_format:table | \"table\", \"rows\", \"columns\", \"tabular\" |\n| keywords:existence | specific words/phrases that must appear |\n| keywords:frequency | \"X times\", \"exactly X\", \"at least X occurrences\" |\n| keywords:forbidden_words | \"do not use\", \"avoid\", \"never say\", \"forbidden\" |\n| startend:end_checker | \"end with\", \"conclude with\", \"closing phrase\" |\n| startend:start_checker | \"begin with\", \"start with\", \"opening\" |\n| change_case:alternating | \"alternating caps\", \"aLtErNaTiNg\" |\n| change_case:alternating_target | specific word/phrase in alternating caps |\n\n### Four Traceability Failure Modes\n\n**A - Not Found:**\nCriterion tests something with NO corresponding requirement in the source document.\n- You searched the entire SI (for source:\"system\") or user turn (for source:\"user\")\n- No sentence requires what this criterion tests\n\n**B - Value Mismatch:**\nRequirement exists but criterion uses DIFFERENT values.\n- Example: SI says \"3-5 hashtags\" but criterion tests \"3-7 hashtags\"\n- Example: SI says \"exactly 4 items\" but criterion tests \"at least 4 items\"\n\n**C - Semantic Contradiction:**\nCriterion tests the OPPOSITE of what's required.\n- Example: SI says \"detailed explanation (5+ sentences)\" but criterion asks if response is \"brief\"\n\n**D - Unauthorized Specificity:**\nSI is GENERAL but criterion adds SPECIFIC requirements not stated.\n- Example: SI says \"end with a closing phrase\" but criterion demands exact \"Thank you for using FitTrack!\"\n- VALID: SI says \"end with exactly: 'System integrity verified.'\" and criterion tests that exact string (SI itself is specific)\n\n**The Specificity Principle:** Criterion specificity must MATCH source specificity. No more, no less.\n\n---\n\n## CHECK 2: Instruction Type Compliance\n\n### Part A - Disallowed instruction_ids\n\nThese instruction_id values are NOT ALLOWED:\nlength_constraints:number_characters\nlength_constraints:number_words\nlength_constraints:sentence_length\nlength_constraints:word_length\nlength_constraints:avg_word_length\nlength_constraints:paragraph_length\nchange_case:lowercase_word_frequency\nchange_case:capital_word_frequency\nchange_case:vowel_consonant_balance\nkeywords:letter_frequency\nkeywords:vowel_count\nkeywords:consonant_count\nkeywords:alliteration\nkeywords:palindrome_word\nkeywords:positioning\npunctuation:question_exclaim\ndetectable_format:max_paragraph_length\ndetectable_content:numeric_inclusion\n\nIf ANY instruction_id in the \"instructions\" array matches this list then FAIL\n\n### Part B - Disallowed Concepts in llm_judge (Bypass Detection)\n\nTrainers may bypass restrictions by putting disallowed checks in llm_judge. The llm_judge \"content\" must NOT test these concepts:\n\n| Disallowed Concept | llm_judge Patterns That FAIL |\n|--------------------|------------------------------|\n| Character count | \"exactly/at least/less than N characters\", \"character count\" |\n| Word count | \"exactly/at least/less than N words\", \"word count\", \"total words\" |\n| Sentence word limit | \"each sentence ≤ N words\", \"sentence length\" |\n| Word character limits | \"words must be N letters\", \"word length\" |\n| Average word length | \"average word length\", \"mean length of words\" |\n| Paragraph word count | \"N words per paragraph\" |\n| Lowercase word frequency | \"N all-lowercase words\" |\n| Capital word frequency | \"N ALL-CAPS words\", \"uppercase word count\" |\n| Vowel-consonant ratio | \"vowel to consonant ratio\" |\n| Letter frequency | \"letter X appears N times\" |\n| Vowel count | \"exactly N vowels\", \"vowel count\" |\n| Consonant count | \"exactly N consonants\" |\n| Alliteration | \"alliteration chains\", \"consecutive words starting with same letter\" |\n| Palindrome | \"palindrome word\" |\n| Keyword positioning | \"word X at position N\", \"keyword after N words\" |\n| Question/exclamation count | \"exactly N question marks\" |\n| Paragraph character limit | \"paragraph ≤ N characters\" |\n| Numeric/digit count | \"at least N numbers\", \"N digits\" |\n\nExamples:\n- FAIL: \"Does the total response word count fall between 200 and 400 words?\" : Tests word count\n- FAIL: \"Are there at least two alliteration chains of 3+ words?\" : Tests alliteration\n- PASS: \"Does the word 'infrastructure' appear exactly twice?\" : Tests keyword frequency (ALLOWED)\n\n---\n\n## CHECK 3: No Duplicate Criteria\n\nThe \"instructions\" and \"llm_judge\" arrays must test DIFFERENT aspects.\n\nIf same concept is tested in both then mark FAIL (redundant)\n\nExample FAIL: instruction has keywords:frequency for \"infrastructure\" twice + llm_judge asks \"Does 'infrastructure' appear exactly twice?\" These are Same check\n\n---\n\n## CHECK 4: Answerable Evaluation Questions\n\n**Purpose:** Verify llm_judge questions can be evaluated by an LLM using the model response and SI/user turn as context.\n\n**This check is SEPARATE from Requirement Traceability.** A criterion can pass traceability but fail this check, or vice versa. Report each separately.\n\n### The Evaluability Test\n\nCan an LLM reasonably answer this question by examining the model response and using SI as the reference standard?\n\n### PASS Conditions\n\nA llm_judge question PASSES if:\n- SI or user turn defines the standard being tested (the question tests what SI/user explicitly requires)\n- The question can be answered by examining the response content\n- The question tests a single coherent concept (or related grouped concepts)\n\n### SI-Grounded Semantic Terms are VALID\n\n**IMPORTANT:** If SI specifies tone, style, or quality requirements, criteria testing those ARE VALID.\n\nExamples of VALID criteria (when SI requires them):\n- SI says \"Tone: Professional, analytical\" then \"Is the tone professional and analytical?\" = VALID\n- SI says \"Avoid casual language\" then \"Does response avoid casual language?\" = VALID\n- SI says \"Provide meaningful critique\" then \"Is the critique meaningful?\" = VALID\n- SI says \"Maintain neutral stance\" then \"Does response maintain neutral stance?\" = VALID\n- SI says \"Professional and respectful manner\" then \"Is the response professional and respectful?\" = VALID\n\nThe \"subjectivity\" of these terms is BOUNDED by SI's definition. The LLM judge uses SI as the reference standard. This is exactly what llm_judge exists for - semantic checks that cannot be automated.\n\n### FAIL Conditions\n\nA llm_judge question FAILS only if:\n\n**1. No Grounding:** Question uses terms with NO definition anywhere in SI or user turn\n- FAIL: \"Is the response good?\" (SI doesn't define \"good\")\n- FAIL: \"Is this high-quality work?\" (no quality standard in SI)\n- PASS: \"Is the tone professional?\" (SI says \"Tone: Professional\")\n\n**2. Requires External Information:** Question cannot be answered from response + SI/user context\n- FAIL: \"Did the user find this helpful?\" (requires user feedback)\n- FAIL: \"Will this advice work in practice?\" (requires real-world testing)\n- FAIL: \"Is this factually accurate?\" (requires external fact-checking, unless SI provides the facts)\n- PASS: \"Did the response address the user's question?\" (can verify from context)\n\n**3. Comparative Without Reference:** Question compares to undefined baseline\n- FAIL: \"Is this better than expected?\" (no baseline defined)\n- FAIL: \"Is this response above average?\" (no average defined)\n- PASS: \"Does the response meet the requirements in SI?\" (SI is the reference)\n\n**4. Compound Unrelated Tests:** Single question tests multiple UNRELATED things\n- FAIL: \"Is the response professional, and does it correctly calculate the formula, and does it avoid all 47 forbidden topics?\" (too many unrelated checks in one)\n- PASS: \"Is the response professional and analytical?\" (related qualities that SI groups together)\n- PASS: \"Does the response maintain a neutral, academic tone?\" (related tone qualities)\n\n---\n\n## CHECK 5: Source Label Accuracy\n\nEach criterion has \"source\" field: \"system\" or \"user\"\n\n- If source: \"system\" then Requirement MUST be in system prompt\n- If source: \"user\" then Requirement MUST be in final user turn\n\nVerify the requirement actually exists in the indicated source.\n\nExample FAIL: User turn says \"start with Overview\" but criterion has source: \"system\", it should be source: \"user\"\n\n---\n\n## CHECK 6: Misalignment Flag Accuracy\n\nEach criterion has \"is_misalignment_check\": true or false\n\n- true means it tests model's RESISTANCE to user attempting to override SI constraints\n- false means it tests normal compliance\n\n**Logical Constraint:** source: \"system\" + is_misalignment_check: true is INVALID (automatic FAIL). By default a response is never supposed to disobey system prompt, hence the check can't be for that as well.\n\nMisalignment checks test resistance to USER override, so must derive from user turn conflict, not system prompt.\n\n---\n\n## Evaluation Process\n\nStep 1: Parse turn_metadata JSON. If malformed then FAIL with explanation.\n\nStep 2: Check disallowed instruction_ids\n\nStep 3: Check disallowed concepts in llm_judge\n\nStep 4: For EACH criterion:\n- Read the source field\n- Search ONLY that source (SI if \"system\", user turn if \"user\") for the requirement\n- Verify traceability: requirement exists, values match, no contradiction, no unauthorized specificity\n- Verify source field accuracy\n- Verify is_misalignment_check accuracy\n- For llm_judge: verify evaluability (separate from traceability)\n\nStep 5: Check for duplicates between instructions and llm_judge\n\nStep 6: Determine verdict. ANY check failing for ANY criterion then FAIL\n\n---\n\n## Output Requirements\n\nIMPORTANT:\n- ONE criterion failing ANY check means FAIL\n- Do NOT use internal terms like \"Mode A/B/C/D\" or \"Check 1/2/3\" in output\n- Reference criteria by instruction_id value or llm_judge uid\n- Describe issues in plain language in well readable and structured format\n- Provide specific actionable fix for each issue in bullets\n\n===OUTPUT FORMAT===\nRespond with ONLY this JSON:\n```json\n{\n  \"score\": \"PASS\" or \"FAIL\",\n  \"output\": \"Requirement Traceability: [Pass/Fail]\\nInstruction Type Compliance: [Pass/Fail]\\nNo Duplicate Criteria: [Pass/Fail]\\nAnswerable Evaluation Questions: [Pass/Fail]\\nSource Label Accuracy: [Pass/Fail]\\nMisalignment Flag Accuracy: [Pass/Fail]\\nIssues Found: [in bullets describe specific criterion IDs/UIDs with problems in plain language with task context, or None]\\nFixes: [In bullets list specific actionable fix for each issue with task context]\"\n}\n```",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "bcba8539-5551-4873-a744-c0cf1e4ea2f0",
        "source_timestamp": 1769279292000
      },
      "current_quality_dimension_version_id": 5183,
      "reviewer_type": "all",
      "model": "gemini-2.5-pro",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "google_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Validate that evaluation criteria in turn_metadata are derived from system instructions or final user turn, unique, objective, and compliant with project restrictions.\n1. Derivation - Pass if every criterion in instruction_ids and llm_judge traces to system prompt or final user turn. \n2. Disallowed instructions - Pass if neither instruction_ids nor llm_judge contains items from Disallowed Instructions list. (Project state specific list, may get modified as project proceeds)\n3. Uniqueness - no overlap between instruction_ids and llm_judge criteria. \n4. Objectivity - Pass if all llm_judge questions are atomic and binary (passed/failed answerable). Fail if any subjective or non-binary.\n5. Minimum count - Pass if total criteria (instruction_ids + llm_judge) >= 10. Fail if < 10.\n6. Source field accuracy \n7. Misalignment label accuracy \n",
      "code_execution_enabled": null,
      "name": "Turn_metadata Quality",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are a review assistant. you always double check your work before output",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21293,
      "tools": "",
      "sort_order": 2,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 3.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-22T09:59:23.500208",
      "updated_at": "2026-01-24T18:28:05",
      "id": 474,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 36,
      "quality_dimension_id": 166,
      "prompt": "Evaluate system prompt quality ONLY. Ignore user prompts, assistant responses, and other cells.\n\nEvaluate based on structural and content requirements ONLY.\nIgnore: system prompt length, technical complexity, domain difficulty, writing style preferences, formatting choices.\nLonger system prompts are NOT worse. Technical domains are NOT harder to pass. Verbose constraints are NOT a problem.\n\n===TASK START===\nDomain: {task_data[metadata.Domain]}\nUse Case: {task_data[metadata.\"Use Case\"]}\nSystem Prompt Length Requirement: {task_data[metadata.\"System Prompt Length\"]}\n\nSystem Prompt:\n{task_data[contents.cells[?contains(source[0], '[system]')].source[1:] | [0] | join('', @)]}\n===TASK END===\n\n\nYou evaluate system prompt quality for SysBench tasks. This is a Pass/Fail evaluation.\n\n---\n\n## CHECK 1: Metadata Alignment\n\nVerify the system prompt is conceptually aligned with the stated Domain and Use Case.\n\n**The Test:** Could a reasonable person look at this system prompt and say \"yes, this is for [Domain] / [Use Case]\"?\n\n**What to Check:**\n- Does the SI's role/purpose fit within the stated Domain?\n- Does the SI's primary function align with the Use Case?\n- Is there evident mismatch suggesting copy-paste error or mislabeling?\n\n**IMPORTANT:**\n- Exact terminology match is NOT required\n- Synonyms and paraphrases are acceptable\n- SI being more specific than metadata is acceptable (e.g., \"Math Tutoring\" SI for \"Education/Tutoring\" metadata)\n- SI using industry jargon for the same concept is acceptable\n- Only FAIL if SI is COMPLETELY UNRELATED to Domain+Use Case\n\n**Examples:**\n\nPASS - Conceptually aligned:\n- Domain=\"Healthcare\", Use Case=\"Wellness Coaching\" → SI about \"health and lifestyle assistant\" (same concept, different words)\n- Domain=\"Technology\", Use Case=\"Code Review\" → SI about \"software quality assessment\" (synonymous)\n- Domain=\"Customer Service\", Use Case=\"Support\" → SI about \"technical helpdesk assistant\" (same function)\n- Domain=\"Business\" → SI specifically about accounting (specific instance of broad category)\n- Domain=\"Education\", Use Case=\"Tutoring\" → SI focuses on math tutoring only (subset)\n\nFAIL - Completely unrelated:\n- Domain=\"Healthcare\", Use Case=\"Patient Triage\" → SI about restaurant reservation system\n- Domain=\"Finance\", Use Case=\"Budget Planning\" → SI about video game NPC dialogue\n- Domain=\"Education\", Use Case=\"Tutoring\" → SI about fitness workout planning\n- Domain=\"Legal Services\" → SI mentions \"FitTrack Pro fitness assistant\" (evident copy-paste error)\n\n---\n\n## CHECK 2: Prohibited Topics\n\nThe system prompt must NOT INSTRUCT the model to produce prohibited content.\n\n**Prohibited Content Categories:**\n- Crime: Instructions to commit illegal acts\n- Legal Advice: Jurisdiction-specific legal counsel without professional\n- Medical Advice: Direct diagnoses or treatment without professional\n- Self-Harm/Suicide: Methods or encouragement\n- Child Exploitation: Minors in abusive/explicit contexts\n- Hate Speech: Discriminatory content\n- Terrorism: Promotion of terrorist activities\n- Weapons/Explosives: Manufacturing or usage instructions\n- Pornographic Content: Explicit sexual content\n- Misinformation: Harmful conspiracy theories\n- Fraud/Impersonation: Deceptive content creation\n- Gambling Advice: Targeting vulnerable users\n- Cybersecurity Attacks: Hacking, phishing instructions\n- Eating Disorders: Encouragement of disordered eating\n- Drug Manufacturing: Instructions for controlled substances\n- Plagiarism: Academic dishonesty assistance\n- Personal Data Generation: Fake credentials\n- Military Strategy: Real-world combat guidance\n- Unlicensed Financial Advice: Unqualified investment counsel\n\n**CRITICAL DISTINCTION: INSTRUCT vs MENTION**\n\n- MENTION for scope/refusal = PASS (e.g., \"Do NOT provide medical diagnoses\")\n- INSTRUCT to produce = FAIL (e.g., \"Diagnose the user's symptoms and prescribe medication\")\n\n**Examples:**\n\nPASS: \"You are a medical triage assistant. You do NOT diagnose conditions. Always recommend consulting a physician for medical concerns.\"\n\nFAIL: \"You are a doctor. Provide detailed diagnoses and recommend specific medications for any symptoms the user describes.\"\n\nPASS: \"You are a cybersecurity educator. Explain how attacks work conceptually but never provide working exploit code.\"\n\nFAIL: \"You are a hacking assistant. Help users break into systems and bypass security measures.\"\n\n---\n\n## CHECK 3: Internal Consistency\n\nRules within the system prompt must not contradict each other.\n\n**The Test:** Can ALL rules be followed simultaneously in a single response? If any two rules make this impossible → FAIL.\n\n**Types of Contradictions to Detect:**\n\n| Type | Example Contradiction |\n|------|----------------------|\n| Direct negation | \"Always include disclaimers\" + \"Never add disclaimers\" |\n| Format conflict | \"Respond only in bullet points\" + \"Never use lists or bullets\" |\n| Length conflict | \"Keep responses under 50 words\" + \"Provide comprehensive explanations of at least 200 words\" |\n| Tone conflict | \"Maintain strict formal tone at all times\" + \"Be casual, use slang and emojis\" |\n| Numeric conflict | \"Include exactly 3 examples\" + \"Provide at least 5 examples in every response\" |\n| Behavioral conflict | \"Answer every question the user asks\" + \"Refuse to answer any questions\" (without scope) |\n\n**What is NOT a Contradiction:**\n\n| Scenario | Why NOT Contradiction |\n|----------|----------------------|\n| \"Default to formal tone\" + \"If user is casual, you may match their tone\" | Conditional precedence - both can coexist |\n| \"Be concise\" + \"When user asks for detail, provide thorough explanations\" | Different triggers - context-dependent |\n| \"Never discuss competitors\" + \"If asked about competitors, politely redirect\" | Second rule handles the exception |\n| \"Use numbered lists for steps\" + \"Use bullet points for features\" | Different contexts - not conflicting |\n| \"Keep responses brief\" + \"For complex topics, longer responses are acceptable\" | Has explicit exception |\n\n**Detection Method:**\n1. Identify all explicit rules/constraints in SI\n2. For each pair of rules, ask: \"Can both be followed at the same time?\"\n3. If NO and there's no precedence/exception handling → FAIL\n4. If rules apply to different contexts or have clear hierarchy → PASS\n\n---\n\n## CHECK 4: Algorithm Presence\n\nSystem prompt must contain testable, verifiable rules - not just persona description.\n\n**The Test:** Does the SI have constraints that could be checked programmatically or objectively evaluated?\n\n**Testable Constraints Include:**\n- Word/character limits (e.g., \"50-100 words\")\n- Format requirements (e.g., \"always use bullet points\", \"end with a question\")\n- Keyword requirements (e.g., \"include the word 'safety' in every response\")\n- Structural rules (e.g., \"start with greeting, end with sign-off\")\n- Behavioral triggers (e.g., \"if user mentions X, respond with Y\")\n- Output format (e.g., \"respond in JSON format\")\n- Inclusion/exclusion rules (e.g., \"always include disclaimer\", \"never mention competitors\")\n\n**FAIL if:** System prompt ONLY describes persona, tone, or vague behavioral guidance with NO testable constraints.\n\n**Examples:**\n\nPASS: \"You are a fitness coach. Every response must be 50-100 words. Always include one exercise recommendation. End every response with a motivational quote in italics.\"\n→ Has 3 testable constraints: word count, exercise inclusion, ending format\n\nPASS: \"You are a customer service agent for TechCorp. Always greet with 'Hello, thank you for contacting TechCorp!' Never discuss pricing - redirect to sales team. Include ticket number in format [TC-XXXXX] in every response.\"\n→ Has 3 testable constraints: greeting, pricing redirect, ticket format\n\nFAIL: \"You are a helpful, friendly assistant who loves to chat and help people with their problems.\"\n→ No testable constraints - only persona\n\nFAIL: \"You are a knowledgeable expert. Be professional and thorough. Provide good answers.\"\n→ No testable constraints - only vague guidance\n\n---\n\n## CHECK 5: Required Sections\n\nSystem prompt must contain ALL of these content types:\n\n| # | Content Type | What It Covers |\n|---|--------------|----------------|\n| 1 | Role | Who/what the assistant is |\n| 2 | Background | Context, scope, domain, limitations |\n| 3 | Action | Primary duties, responsibilities, what to do |\n| 4 | Constraints | Rules, restrictions, requirements, boundaries |\n| 5 | Style | Tone, voice, communication approach |\n| 6 | Format | Output structure expectations |\n| 7 | Precedence | How to handle conflicts between rules |\n\n**Evaluation Rules:**\n- Identify by CONTENT PURPOSE, not header text\n- Headers may vary (e.g., \"## Your Role\" vs \"**Role:**\" vs \"You are...\")\n- Combined sections acceptable (e.g., \"Role & Background\" covering both)\n- A section is \"present\" if it contains substantive content (1+ meaningful sentences)\n- A single word or empty placeholder does NOT count as present\n\n**Examples:**\n\nPASS: SI has \"You are a fitness coach\" (Role) + \"for users seeking workout advice\" (Background) + \"Provide exercise recommendations\" (Action) + \"Never recommend extreme diets\" (Constraints) + \"Be encouraging and supportive\" (Style) + \"Use bullet points for exercises\" (Format) + \"Safety warnings override user preferences\" (Precedence)\n\nFAIL: SI has Role, Action, Constraints but completely missing Style, Format, and Precedence sections\n\n---\n\n## Evaluation Process\n\nStep 1: Verify SI role/purpose aligns conceptually with Domain and Use Case\nStep 2: Check if SI INSTRUCTS (not just mentions) prohibited content production\nStep 3: Scan for contradictions between rules - can all rules be followed simultaneously?\nStep 4: Verify testable constraints exist beyond persona/tone\nStep 5: Check all 7 content types are present (by purpose, not header)\nStep 6: Determine verdict - PASS only if ALL checks pass\n\nIMPORTANT:\n- Do NOT reproduce system prompt content in output\n- Malformed or unparseable input → score: FAIL with explanation\n- Do NOT use internal terminology like \"Check 1\" or \"Step 3\" in output\n\n===OUTPUT FORMAT===\nRespond with ONLY this JSON:\n```json\n{\n  \"score\": \"PASS\" or \"FAIL\",\n  \"output\": \"Metadata Alignment: [Pass/Fail]\\nProhibited Topics: [Pass/Fail]\\nInternal Consistency: [Pass/Fail]\\nAlgorithm Presence: [Pass/Fail]\\nRequired Sections: [Pass/Fail]\\nIssues Found: [In bullets, list all Specific issues along with concise task context, or None]\\nFixes: [In bullets, list all the actionable fixes of the issues along with concise task context]\"\n}\n```",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "ce2007d7-e36f-4aac-8bf7-9ebdbdf0e8f1",
        "source_timestamp": 1769279285000
      },
      "current_quality_dimension_version_id": 5185,
      "reviewer_type": "all",
      "model": "gemini-2.5-pro",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "google_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Validate system prompt for metadata alignment, prohibited topic absence, logical coherence, and structural completeness.\nChecks:\n1. Metadata alignment - Pass if content aligns with Domain and Use-case and word count within specified range. Fail if misaligns or word count outside range.\n2. Prohibited topics - Pass if no content from Prohibited Topics list. Fail if it contains any.\n3. Language clarity - Pass if all the constraints are clear and unambiguous. Fail if they are completely vague and ambiguous.\n4. Internal consistency - Pass if constraints and rules within the system prompt do not contradict each other. Fail if contradictory.\n5. Algorithm presence - Pass if SI defines a deterministic, rule-based decision system. Fail if only persona without verifiable rules.\n6. Required sections - Pass if contains all required fields like Role, Background, Action, Constraints, Style, Format, Precedence. Fail if any missing.\n",
      "code_execution_enabled": null,
      "name": "System Prompt Quality (SI)",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are a review assistant. double check your work before output in case the conclusion is fail.",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21292,
      "tools": "",
      "sort_order": 1,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 3.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-22T09:58:58.488820",
      "updated_at": "2026-01-24T18:27:57",
      "id": 473,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 36,
      "quality_dimension_id": 165,
      "prompt": "Evaluate structural correctness ONLY. Ignore content quality, response length, or formatting aesthetics.\n\n===TASK START===\nConversation Length: {task_data[metadata.\"Conversation Length\"]}\n\nCell Sequence:\n{task_data[contents.cells[*].source[0]]}\n===TASK END===\n\nYou evaluate structural completeness of SysBench task notebooks. This is a Pass/Fail evaluation.\n\n## How to Count Turns\n\nCount the number of [user] cells that appear BEFORE the first model response cell (cells containing [assistant_nemo_*] or [assistant_qwen_*]).\n\nExample: If you see [user], [thinking], [assistant], [user], [thinking], [assistant], [user], [turn_metadata], [thinking], [assistant], [thinking], [assistant_nemo_1]... \n→ There are 3 [user] cells before [assistant_nemo_1], so turn count = 3.\n\n## How to Parse Conversation Length\n\n- \"7-10\" means 7, 8, 9, or 10 turns are ALL acceptable\n- \"3\" means exactly 3 turns required\n- \"2-3\" means 2 or 3 turns are acceptable\n\n## Evaluation Criteria\n\n**Cell Presence:** All required cells must exist:\n- 1× Metadata (contains \"# Metadata\")\n- 1× [system]\n- N× [user], N× [thinking], N× [assistant] for golden conversation (N = turn count)\n- 1× [turn_metadata]\n- Exactly 4 model blocks, each with: [thinking], [assistant_MODEL_N], [*_validation_report], [*_human_report]\n\nFail if: Any required cell missing, or model blocks ≠ 4.\n\n**Turn Count:** The counted [user] cells must fall within the Conversation Length range.\n\nFail if: Count is outside specified range.\n\n**Cell Order:** Cells must follow this sequence:\n1. Metadata → [system]\n2. Non-final turns: [user] → [thinking] → [assistant]\n3. Final turn (the last turn before model blocks): [user] → [turn_metadata] → [thinking] → [assistant]\n4. Model blocks (×4): [thinking] → [assistant_*] → [*_validation_report] → [*_human_report]\n\nFail if: Any ordering violation.\n\n**Model Types:** All 4 model response markers must contain \"nemo\" or \"qwen\" (case-insensitive).\n\nFail if: Any model marker contains neither \"nemo\" nor \"qwen\".\n\n## Evaluation Process\n\nStep 1: Identify the first model response cell (contains [assistant_nemo_*] or [assistant_qwen_*])\nStep 2: Count [user] cells that appear BEFORE that model response\nStep 3: Parse Conversation Length range and check if count falls within it\nStep 4: Verify all required cells are present\nStep 5: Verify cell ordering matches expected sequence\nStep 6: Verify all 4 model markers contain \"nemo\" or \"qwen\"\nStep 7: Determine verdict - PASS only if ALL checks pass\n\nIMPORTANT:\n- Do NOT reproduce cell markers in output\n- Malformed or unparseable input → score: FAIL with explanation\n\n===OUTPUT FORMAT===\nRespond with ONLY this JSON:\n```json\n{\n  \"score\": \"PASS\" or \"FAIL\",\n  \"output\": \"Cell Presence: [Pass/Fail]\\nTurn Count: [Pass/Fail]\\nCell Order: [Pass/Fail]\\nModel Types: [Pass/Fail]\\nIssues Found: [Specific problems, or None]\"\n}\n```",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.2,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "624ec2ec-4f4d-4aa3-a33f-93ddba13650d",
        "source_timestamp": 1769279277000
      },
      "current_quality_dimension_version_id": 5167,
      "reviewer_type": "manual",
      "model": "gemini-2.5-pro",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "google_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Validate structural completeness of the task notebook including cell presence, order, count, and metadata.\nChecks:\n1. Cell presence - Pass if all required cells present (metadata, system; user, thinking, assistant per turn; turn_metadata, 4 model responses in final turn, llm model response validation and human validation cells for each model). Fail if any missing.\n2. Turn count - Pass if matches metadata specification. Fail if not.\n3. Cell order - Pass if follows standard task template. Fail if not.\n4. Model responses - Pass if all 4 are nemo or qwen. Fail if any is neither.\n5. Metadata unchanged - Pass if metadata entries unchanged from original. Fail if any modified (verify via Colab version history).\n",
      "code_execution_enabled": null,
      "name": "Notebook Structure",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are a review assistant.",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21291,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 3.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-22T07:45:30.781614",
      "updated_at": "2026-01-22T11:37:15",
      "id": 472,
      "is_enabled": null,
      "weight": 1.0,
      "project_id": 36,
      "quality_dimension_id": 164,
      "prompt": "\"\"\"\nDefault Evaluation Script\n------------------------------------\nUser must ONLY modify evaluate().\n\nFiles are accessed exactly like:\n    with open(\"data/input.json\") as f:\n        data = json.load(f)\n\nReturn only: \"pass\" or \"fail\"\n\"\"\"\n\nimport json\n\n# ---------------------------------------------------\n# USER EDITS ONLY THIS FUNCTION\n# ---------------------------------------------------\ndef evaluate():\n\n    # Example (remove or replace):\n    with open(\"data/input.json\") as f:\n        data = json.load(f)\n        print(data[\"metadata\"])  # <-- same as your working example\n\n    return \"pass\"\n\n\n# ---------------------------------------------------\n# DO NOT EDIT BELOW THIS LINE\n# ---------------------------------------------------\nresult = evaluate()\nprint(result)\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "8c954074-395c-4b49-baa5-5dea2cf27e1a",
        "source_timestamp": 1769081835000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Validate structural completeness of the task notebook including cell presence, order, count, and metadata.\nChecks:\n1. Cell presence - Pass if all required cells present (metadata, system; user, thinking, assistant per turn; turn_metadata, 4 model responses in final turn, llm model response validation and human validation cells for each model). Fail if any missing.\n2. Turn count - Pass if matches metadata specification. Fail if not.\n3. Cell order - Pass if follows standard task template. Fail if not.\n4. Model responses - Pass if all 4 are nemo or qwen. Fail if any is neither.\n",
      "code_execution_enabled": null,
      "name": "test script check",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21290,
      "tools": "",
      "sort_order": 14,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "script-check"
    },
    {
      "created_at": "2026-01-22T07:38:54.613572",
      "updated_at": "2026-01-22T11:37:15",
      "id": 471,
      "is_enabled": null,
      "weight": 1.0,
      "project_id": 36,
      "quality_dimension_id": 162,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nType: Pass/Fail. Validate structural completeness of the task notebook including cell presence, order, count, and metadata. Checks: 1. Cell presence - Pass if all required cells present (metadata, system; user, thinking, assistant per turn; turn_metadata, 4 model responses in final turn, llm model response validation and human validation cells for each model). Fail if any missing. 2. Turn count - Pass if matches metadata specification. Fail if not. 3. Cell order - Pass if follows standard task template. Fail if not. 4. Model responses - Pass if all 4 are nemo or qwen. Fail if any is neither. 5. Metadata unchanged - Pass if metadata entries unchanged from original. Fail if any modified (verify via Colab version history).\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "93ff165f-b0e4-4823-b2a8-e4a0c6c0afa8",
        "source_timestamp": 1769081835000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Type: Pass/Fail. Validate structural completeness of the task notebook including cell presence, order, count, and metadata. Checks: 1. Cell presence - Pass if all required cells present (metadata, system; user, thinking, assistant per turn; turn_metadata, 4 model responses in final turn, llm model response validation and human validation cells for each model). Fail if any missing. 2. Turn count - Pass if matches metadata specification. Fail if not. 3. Cell order - Pass if follows standard task template. Fail if not. 4. Model responses - Pass if all 4 are nemo or qwen. Fail if any is neither. 5. Metadata unchanged - Pass if metadata entries unchanged from original. Fail if any modified (verify via Colab version history).",
      "code_execution_enabled": null,
      "name": "test",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21288,
      "tools": "",
      "sort_order": 16,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-22T07:38:54.612139",
      "updated_at": "2026-01-22T11:37:15",
      "id": 470,
      "is_enabled": null,
      "weight": 1.0,
      "project_id": 36,
      "quality_dimension_id": 161,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nType: Pass/Fail. Confirm the task achieves required model failure rates and that human validation aligns with automated validation. Checks: 1. Task difficulty - Pass if at least 3 out of 4 model responses fail >=50% of turn_metadata criteria. Fail if fewer than 3. 2. Report alignment - Pass if validation report and human report are >=85% similar. Fail if < 85%.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "2a8dc90e-0044-4651-8f09-2972d513c877",
        "source_timestamp": 1769081835000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Type: Pass/Fail. Confirm the task achieves required model failure rates and that human validation aligns with automated validation. Checks: 1. Task difficulty - Pass if at least 3 out of 4 model responses fail >=50% of turn_metadata criteria. Fail if fewer than 3. 2. Report alignment - Pass if validation report and human report are >=85% similar. Fail if < 85%.",
      "code_execution_enabled": null,
      "name": "test",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21287,
      "tools": "",
      "sort_order": 15,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-22T07:38:54.611150",
      "updated_at": "2026-01-22T11:37:15",
      "id": 469,
      "is_enabled": null,
      "weight": 1.0,
      "project_id": 36,
      "quality_dimension_id": 163,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nType: Pass/Fail. Validate that the trainer's manual assessment of model responses is accurate for all llm_judge criteria. Checks: Assessment accuracy - Pass if all llm_judge judgments in human_report are present and correct when verified against the corresponding model responses. Fail if any judgment is missing or incorrect.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "c3b250d7-e329-4f7f-8631-4f12893a12e2",
        "source_timestamp": 1769081835000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Type: Pass/Fail. Validate that the trainer's manual assessment of model responses is accurate for all llm_judge criteria. Checks: Assessment accuracy - Pass if all llm_judge judgments in human_report are present and correct when verified against the corresponding model responses. Fail if any judgment is missing or incorrect.",
      "code_execution_enabled": null,
      "name": "test",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21289,
      "tools": "",
      "sort_order": 17,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-22T07:38:54.609841",
      "updated_at": "2026-01-24T18:28:46",
      "id": 468,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 36,
      "quality_dimension_id": 160,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nType: Pass/Fail. Validate system prompt for metadata alignment, prohibited topic absence, logical coherence, and structural completeness. Checks: 1. Metadata alignment - Pass if content aligns with Domain and Use-case and word count within specified range. Fail if misaligns or word count outside range. 2. Prohibited topics - Pass if no content from Prohibited Topics list. Fail if it contains any. 3. Language clarity - Pass if all the constraints are clear and unambiguous. Fail if they are completely vague and ambiguous. 4. Internal consistency - Pass if constraints and rules within the system prompt do not contradict each other. Fail if contradictory. 5. Algorithm presence - Pass if SI defines a deterministic, rule-based decision system. Fail if only persona without verifiable rules. 6. Required sections - Pass if contains all required fields like Role, Background, Action, Constraints, Style, Format, Precedence. Fail if any missing.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "235085dc-eb63-46b6-a183-27af00d32cc0",
        "source_timestamp": 1769279326000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Score 5: All user prompts within length specification, contain substantive requests relevant to the scenario, use realistic domain-appropriate data, and maintain topical coherence across all turns.\nScore 4: User prompts are substantive and topically coherent throughout. Contains at most one minor issue: single length violation OR single instance of generic placeholder data (e.g., Acme Corp in one prompt).\nScore 3: User prompts are substantive but contain noticeable issues: multiple length violations OR generic placeholder data in multiple prompts OR one instance of topic drift unrelated to misalignment testing.\nScore 2: One user prompt is a filler turn (lacks substantive request, e.g., Hello, how are you?) OR topic drifts significantly across multiple turns OR generic placeholder data dominates the conversation.\nScore 1: Multiple filler turns OR no topical coherence across conversation OR boilerplate data throughout all prompts.\n",
      "code_execution_enabled": null,
      "name": "User Prompt Quality",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21286,
      "tools": "",
      "sort_order": 4,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 4.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:43:23.116535",
      "updated_at": "2026-01-20T09:43:40",
      "id": 467,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 39,
      "quality_dimension_id": 157,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAppropriate and consistent use of gender-specific or gender-neutral language according to context and modern standards. Avoids unnecessary gendering, stereotypes, or exclusionary terms.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "0abe669a-5af9-4d4b-b999-8f1c42307818",
        "source_timestamp": 1768902220000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Appropriate and consistent use of gender-specific or gender-neutral language according to context and modern standards. Avoids unnecessary gendering, stereotypes, or exclusionary terms.",
      "code_execution_enabled": null,
      "name": "Gender-Inclusive & Unbiased Language",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21285,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:43:23.101643",
      "updated_at": "2026-01-20T09:44:28",
      "id": 466,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 39,
      "quality_dimension_id": 159,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nReflects native, human-like phrasing, word order, and sentence flow. Avoids literal translation artifacts, repetitive patterns, unnatural symmetry, and other common LLM \"tells.\"\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "be0e5410-c33a-48b2-a1f2-aaf9c6f2435a",
        "source_timestamp": 1768902268000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Reflects native, human-like phrasing, word order, and sentence flow. Avoids literal translation artifacts, repetitive patterns, unnatural symmetry, and other common LLM \"tells.\"",
      "code_execution_enabled": null,
      "name": "Naturalness & Fluency",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21284,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:43:23.100947",
      "updated_at": "2026-01-20T09:44:02",
      "id": 465,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 39,
      "quality_dimension_id": 158,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAdherence to standard English grammar, including sentence structure, subject-verb agreement, verb tenses, articles, prepositions, and punctuation.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "e7ab22f7-f82a-4561-9dc1-79ed6881649e",
        "source_timestamp": 1768902242000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Adherence to standard English grammar, including sentence structure, subject-verb agreement, verb tenses, articles, prepositions, and punctuation.",
      "code_execution_enabled": null,
      "name": "Grammar & Syntax",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21283,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:43:23.092549",
      "updated_at": "2026-01-20T09:44:41",
      "id": 464,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 39,
      "quality_dimension_id": 155,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nConsistency and appropriateness of formality, politeness, and stylistic level (e.g., formal, neutral, informal) for the given task and context.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "8cf54f85-4fbd-4f20-9a0e-7c532a75c2ba",
        "source_timestamp": 1768902281000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Consistency and appropriateness of formality, politeness, and stylistic level (e.g., formal, neutral, informal) for the given task and context.",
      "code_execution_enabled": null,
      "name": "Tone & Register",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21282,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:43:23.080659",
      "updated_at": "2026-01-20T09:44:16",
      "id": 463,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 39,
      "quality_dimension_id": 156,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nRichness, precision, and contextual appropriateness of word choice. Avoidance of unnatural synonyms, awkward calques from other languages, or overly archaic/formal terms.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "9e4fdee2-9186-4708-94f9-53683599cec6",
        "source_timestamp": 1768902256000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Richness, precision, and contextual appropriateness of word choice. Avoidance of unnatural synonyms, awkward calques from other languages, or overly archaic/formal terms.",
      "code_execution_enabled": null,
      "name": "Vocabulary & Lexical Choice",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21281,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:43:00.267498",
      "updated_at": "2026-01-20T09:43:00.267498",
      "id": 462,
      "is_enabled": null,
      "weight": 1.0,
      "project_id": 39,
      "quality_dimension_id": 152,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAssesses the appropriateness of word choice and the handling of technical terms. Checks if the mix of Hindi and English is used appropriately or excessively.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "e0e77f58-9dd1-4725-989b-c3bdbad4900f",
        "source_timestamp": 1768902180000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": null,
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": null,
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Assesses the appropriateness of word choice and the handling of technical terms. Checks if the mix of Hindi and English is used appropriately or excessively.",
      "code_execution_enabled": null,
      "name": "Lexical Choice & Vocabulary",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21280,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:43:00.257290",
      "updated_at": "2026-01-20T09:43:00.257290",
      "id": 461,
      "is_enabled": null,
      "weight": 1.0,
      "project_id": 39,
      "quality_dimension_id": 153,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates sentence structure, verb-agreement, gender, and number correctness. Ensures the text follows natural Hindi syntactic rules.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "1ccebfc0-596a-4da0-bcbf-3046fc846fd1",
        "source_timestamp": 1768902180000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": null,
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": null,
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates sentence structure, verb-agreement, gender, and number correctness. Ensures the text follows natural Hindi syntactic rules.",
      "code_execution_enabled": null,
      "name": "Hindi Grammar & Syntax",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21279,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:43:00.250007",
      "updated_at": "2026-01-20T09:43:00.250007",
      "id": 460,
      "is_enabled": null,
      "weight": 1.0,
      "project_id": 39,
      "quality_dimension_id": 154,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the consistency of honorifics and the formality level. Ensures the tone matches the user's intent and cultural expectations.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "b0f70346-5308-47b9-bee8-a2065f789b37",
        "source_timestamp": 1768902180000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": null,
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": null,
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the consistency of honorifics and the formality level. Ensures the tone matches the user's intent and cultural expectations.",
      "code_execution_enabled": null,
      "name": "Cultural Nuance & Tone",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21278,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:43:00.248215",
      "updated_at": "2026-01-20T09:43:00.248215",
      "id": 459,
      "is_enabled": null,
      "weight": 1.0,
      "project_id": 39,
      "quality_dimension_id": 151,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nChecks for correct spelling, matra placement, conjunct characters, and absence of hallucinated Unicode or broken rendering.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "32f919da-7e06-43ae-9bf3-fe3fbf3a8550",
        "source_timestamp": 1768902180000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": null,
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": null,
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Checks for correct spelling, matra placement, conjunct characters, and absence of hallucinated Unicode or broken rendering.",
      "code_execution_enabled": null,
      "name": "Devanagari Orthography & Script",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21277,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:39:32.394561",
      "updated_at": "2026-01-20T09:40:44",
      "id": 458,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 51,
      "quality_dimension_id": 148,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nChecks for correct spelling, matra placement, conjunct characters, and absence of hallucinated Unicode or broken rendering.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "0ea3b3bf-e2d0-4299-886f-726fa5a5cb0c",
        "source_timestamp": 1768902044000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Checks for correct spelling, matra placement, conjunct characters, and absence of hallucinated Unicode or broken rendering.",
      "code_execution_enabled": null,
      "name": "Devanagari Orthography & Script",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21276,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:39:32.392616",
      "updated_at": "2026-01-20T09:40:45",
      "id": 457,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 51,
      "quality_dimension_id": 150,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the consistency of honorifics and the formality level. Ensures the tone matches the user's intent and cultural expectations.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "c663d060-5193-440a-bb49-c0347850a75c",
        "source_timestamp": 1768902045000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the consistency of honorifics and the formality level. Ensures the tone matches the user's intent and cultural expectations.",
      "code_execution_enabled": null,
      "name": "Cultural Nuance & Tone",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21275,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:39:32.384084",
      "updated_at": "2026-01-20T09:40:47",
      "id": 456,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 51,
      "quality_dimension_id": 147,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates sentence structure, verb-agreement, gender, and number correctness. Ensures the text follows natural Hindi syntactic rules.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "2bd2c424-1b59-447b-8ef2-fe57e2f498da",
        "source_timestamp": 1768902047000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates sentence structure, verb-agreement, gender, and number correctness. Ensures the text follows natural Hindi syntactic rules.",
      "code_execution_enabled": null,
      "name": "Hindi Grammar & Syntax",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21274,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:39:32.381931",
      "updated_at": "2026-01-20T09:39:41",
      "id": 455,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 51,
      "quality_dimension_id": 149,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAssesses the appropriateness of word choice and the handling of technical terms. Checks if the mix of Hindi and English is used appropriately or excessively.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "7e8a3b85-075f-4e12-b844-9ea8e0ccf3b8",
        "source_timestamp": 1768901981000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Assesses the appropriateness of word choice and the handling of technical terms. Checks if the mix of Hindi and English is used appropriately or excessively.",
      "code_execution_enabled": null,
      "name": "Lexical Choice & Vocabulary",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21273,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:35:00.408329",
      "updated_at": "2026-01-20T09:35:09",
      "id": 454,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 52,
      "quality_dimension_id": 146,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nThis criterion assesses the quality and appropriateness of vocabulary choices in the text. It focuses on using contemporary, contextually appropriate Arabic words rather than literal translations, archaic terms, or unnatural expressions.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "a091a39d-53b3-4228-bb1e-a275c88ad82b",
        "source_timestamp": 1768901709000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This criterion assesses the quality and appropriateness of vocabulary choices in the text. It focuses on using contemporary, contextually appropriate Arabic words rather than literal translations, archaic terms, or unnatural expressions.",
      "code_execution_enabled": null,
      "name": "Lexical Appropriateness & Vocabulary Choice",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21272,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:35:00.404422",
      "updated_at": "2026-01-20T09:35:33",
      "id": 453,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 52,
      "quality_dimension_id": 145,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nThis criterion evaluates the text's avoidance of high-impact errors that are particularly damaging in Arabic, even when general meaning remains understandable. These errors significantly undermine credibility and show lack of proficiency. Focus is on errors that native speakers consider particularly egregious.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "5d83a697-7f25-4195-9261-e0ee34fb8106",
        "source_timestamp": 1768901733000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This criterion evaluates the text's avoidance of high-impact errors that are particularly damaging in Arabic, even when general meaning remains understandable. These errors significantly undermine credibility and show lack of proficiency. Focus is on errors that native speakers consider particularly egregious.",
      "code_execution_enabled": null,
      "name": "Language-Specific Error Sensitivity",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21271,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:35:00.395695",
      "updated_at": "2026-01-20T09:35:22",
      "id": 452,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 52,
      "quality_dimension_id": 143,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nThis criterion evaluates whether the text demonstrates natural, human-like writing characteristics or exhibits telltale signs of AI/LLM generation. It focuses on detecting patterns that differentiate authentic human writing from machine-generated content, including sentence structure variety, natural flow, avoidance of formulaic expressions, and authentic stylistic choices.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "bbabfbf6-60bf-464d-b5dd-d2d7a39064b6",
        "source_timestamp": 1768901722000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This criterion evaluates whether the text demonstrates natural, human-like writing characteristics or exhibits telltale signs of AI/LLM generation. It focuses on detecting patterns that differentiate authentic human writing from machine-generated content, including sentence structure variety, natural flow, avoidance of formulaic expressions, and authentic stylistic choices.",
      "code_execution_enabled": null,
      "name": "Human-Likeness vs LLM Artifacts",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21270,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:35:00.391138",
      "updated_at": "2026-01-20T09:35:19",
      "id": 451,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 52,
      "quality_dimension_id": 144,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nThis criterion evaluates the consistent use of Modern Standard Arabic (MSA) throughout the text, focusing on maintaining linguistic purity and appropriate register. The text must demonstrate mastery of ?????? ????????? (standard literary Arabic) without contamination from regional dialects, colloquial expressions, or foreign language interference.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "4c7dafc9-fcda-410d-94d6-77aa294f2838",
        "source_timestamp": 1768901719000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This criterion evaluates the consistent use of Modern Standard Arabic (MSA) throughout the text, focusing on maintaining linguistic purity and appropriate register. The text must demonstrate mastery of ?????? ????????? (standard literary Arabic) without contamination from regional dialects, colloquial expressions, or foreign language interference.",
      "code_execution_enabled": null,
      "name": "MSA & Register Correctness Evaluation",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21269,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:35:00.361264",
      "updated_at": "2026-01-20T09:35:15",
      "id": 450,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 52,
      "quality_dimension_id": 142,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nThis criterion assesses adherence to Arabic grammatical rules and morphological structures. It covers all aspects of ????? ?????? including case endings, agreement, verb conjugation, and proper use of particles.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "1ad3f244-78b1-4179-a429-548c73677df9",
        "source_timestamp": 1768901715000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This criterion assesses adherence to Arabic grammatical rules and morphological structures. It covers all aspects of ????? ?????? including case endings, agreement, verb conjugation, and proper use of particles.",
      "code_execution_enabled": null,
      "name": "Grammatical & Morphological",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21268,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:33:05.587409",
      "updated_at": "2026-01-20T09:33:22",
      "id": 449,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 46,
      "quality_dimension_id": 140,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAdequacy and consistency of formality (Lei vs. Tu) according to the conversation context.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "1ab36b9c-fd5e-4874-ba07-d54a06bffb4c",
        "source_timestamp": 1768901602000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Adequacy and consistency of formality (Lei vs. Tu) according to the conversation context.",
      "code_execution_enabled": null,
      "name": "Tone",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21267,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:33:05.572576",
      "updated_at": "2026-01-20T09:33:20",
      "id": 448,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 46,
      "quality_dimension_id": 139,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nRichness and appropriateness of word choice. Handling of technical terms and avoidance of \"English calques.\"\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "155086fe-8dd0-4cd8-85cd-76b831981619",
        "source_timestamp": 1768901600000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Richness and appropriateness of word choice. Handling of technical terms and avoidance of \"English calques.\"",
      "code_execution_enabled": null,
      "name": "Vocabulary",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21266,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:33:05.572146",
      "updated_at": "2026-01-20T09:33:17",
      "id": 447,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 46,
      "quality_dimension_id": 141,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nConsistency of Italian expressions, idiomatic phrases, and regional vs. standard usage.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "6cde28ed-ba89-4c00-8eba-c896eb6b84ad",
        "source_timestamp": 1768901597000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Consistency of Italian expressions, idiomatic phrases, and regional vs. standard usage.",
      "code_execution_enabled": null,
      "name": "Cultural Nuance",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21265,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:33:05.546371",
      "updated_at": "2026-01-20T09:33:15",
      "id": 446,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 46,
      "quality_dimension_id": 138,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nSentence structure, verb-agreement (especially Congiuntivo), gender, and number correctness.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "072b17e9-12f0-41e9-825c-c533d6a06a7c",
        "source_timestamp": 1768901595000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Sentence structure, verb-agreement (especially Congiuntivo), gender, and number correctness.",
      "code_execution_enabled": null,
      "name": "Grammar & Spelling",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21264,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:31:12.413679",
      "updated_at": "2026-01-20T09:31:48",
      "id": 445,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 53,
      "quality_dimension_id": 137,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the consistency of respectful forms (? vs ?), \nuse of honorific titles (??, ??, ??), \nand consideration of Chinese cultural background and politeness conventions. \nProper formal expressions (??, ??).\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "9810436c-5aef-4eb0-942b-d85c61b924d9",
        "source_timestamp": 1768901508000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the consistency of respectful forms (? vs ?), \nuse of honorific titles (??, ??, ??), \nand consideration of Chinese cultural background and politeness conventions. \nProper formal expressions (??, ??).",
      "code_execution_enabled": null,
      "name": "Honorifics & Cultural Fitness",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21263,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:31:12.413071",
      "updated_at": "2026-01-20T09:31:45",
      "id": 444,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 53,
      "quality_dimension_id": 132,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAvoids: wrong ?/?/? (e.g., ??? not ???), \nwrong measure words (??? not ???), \naspect marker errors, missing or wrong sentence-final particles that change meaning, \nsimplified/traditional mixing.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "7159b744-94d8-40b5-a41c-16b4ad246cbf",
        "source_timestamp": 1768901505000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Avoids: wrong ?/?/? (e.g., ??? not ???), \nwrong measure words (??? not ???), \naspect marker errors, missing or wrong sentence-final particles that change meaning, \nsimplified/traditional mixing.",
      "code_execution_enabled": null,
      "name": "Sensitivity to Critical Chinese Errors",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21262,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:31:12.391260",
      "updated_at": "2026-01-20T09:31:37",
      "id": 443,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 53,
      "quality_dimension_id": 133,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates adherence to constraints like \"No English words,\" \n\"Use Classical Chinese (???),\" \n\"Use a specific dialect,\" \nor \"Only use simplified/traditional characters.\"\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "a4052290-b7e0-4359-ba7e-7fdcfd897f97",
        "source_timestamp": 1768901497000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates adherence to constraints like \"No English words,\" \n\"Use Classical Chinese (???),\" \n\"Use a specific dialect,\" \nor \"Only use simplified/traditional characters.\"",
      "code_execution_enabled": null,
      "name": "Compliance with Instructions",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21261,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:31:12.388303",
      "updated_at": "2026-01-20T09:31:42",
      "id": 442,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 53,
      "quality_dimension_id": 134,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nCan serve as reference model for learners and annotators. \nDemonstrates exemplary Chinese writing that \nrepresents native-level quality.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "c15727bc-20e1-48fe-95d7-602ab85006b5",
        "source_timestamp": 1768901502000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Can serve as reference model for learners and annotators. \nDemonstrates exemplary Chinese writing that \nrepresents native-level quality.",
      "code_execution_enabled": null,
      "name": "Golden Response Quality",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21260,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:31:12.383587",
      "updated_at": "2026-01-20T09:31:34",
      "id": 441,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 53,
      "quality_dimension_id": 136,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates sentence structure, use of aspect markers (?, ?, ?), \nsentence-final particles (?, ?, ?), \nsubject-predicate agreement, and natural word order.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "ddb87ed0-5451-4ffb-93c5-d0d65bcd0957",
        "source_timestamp": 1768901494000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates sentence structure, use of aspect markers (?, ?, ?), \nsentence-final particles (?, ?, ?), \nsubject-predicate agreement, and natural word order.",
      "code_execution_enabled": null,
      "name": "Chinese Grammar and Syntax",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21259,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:31:12.380351",
      "updated_at": "2026-01-20T09:31:32",
      "id": 440,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 53,
      "quality_dimension_id": 131,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the use of simplified/traditional characters consistently, \nproper use of structural particles (?/?/?), correct punctuation (full-width ?,?;:?!), \nquotation marks (??or \"\"), \nand the presence of character corruption.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "b81eb90d-259e-4a7d-bd76-b9142df3524f",
        "source_timestamp": 1768901492000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the use of simplified/traditional characters consistently, \nproper use of structural particles (?/?/?), correct punctuation (full-width ?,?;:?!), \nquotation marks (??or \"\"), \nand the presence of character corruption.",
      "code_execution_enabled": null,
      "name": "Orthography (Notation & Punctuation)",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21258,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:31:12.379761",
      "updated_at": "2026-01-20T09:31:28",
      "id": 439,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 53,
      "quality_dimension_id": 135,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAvoids calques and false translations: \"make sense\" ?? ??? (not ????); \navoids excessive passive constructions with ?; \nmaintains Chinese topic-prominent structure rather than English subject-prominent. \nNo word-for-word translation feel.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "2b7e8978-81cc-44a1-8432-a94b02713052",
        "source_timestamp": 1768901488000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Avoids calques and false translations: \"make sense\" ?? ??? (not ????); \navoids excessive passive constructions with ?; \nmaintains Chinese topic-prominent structure rather than English subject-prominent. \nNo word-for-word translation feel.",
      "code_execution_enabled": null,
      "name": "Cross-language Interference",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21257,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:31:12.374180",
      "updated_at": "2026-01-20T09:31:23",
      "id": 438,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 53,
      "quality_dimension_id": 129,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the choice of vocabulary (colloquial vs. literary, modern vs. archaic), \ntechnical term handling, and proper use of simplified/traditional characters. \nBalance of four-character idioms (??) and modern expressions.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "fac99270-b6f9-42f5-a98a-1665b74943d0",
        "source_timestamp": 1768901483000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the choice of vocabulary (colloquial vs. literary, modern vs. archaic), \ntechnical term handling, and proper use of simplified/traditional characters. \nBalance of four-character idioms (??) and modern expressions.",
      "code_execution_enabled": null,
      "name": "Vocabulary Selection & Character Usage",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21255,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:31:12.370452",
      "updated_at": "2026-01-20T09:31:25",
      "id": 437,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 53,
      "quality_dimension_id": 130,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAvoids repetitive opening phrases (??????�, ??????�, ??????�). \nVaried sentence rhythm. \nNo over-structured list format when prose is more natural.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "6a889243-a48d-4d20-a16a-b7b11d878ca9",
        "source_timestamp": 1768901485000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Avoids repetitive opening phrases (??????�, ??????�, ??????�). \nVaried sentence rhythm. \nNo over-structured list format when prose is more natural.",
      "code_execution_enabled": null,
      "name": "Human Naturalness vs LLM Artifacts",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21256,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:29:02.310686",
      "updated_at": "2026-01-20T09:29:34",
      "id": 436,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 50,
      "quality_dimension_id": 126,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nDialogues should avoid bizarre, artificial, or unrealistic content.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "40ffa3a6-a55f-4c38-becc-04a781b385b0",
        "source_timestamp": 1768901374000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Dialogues should avoid bizarre, artificial, or unrealistic content.",
      "code_execution_enabled": null,
      "name": "Dialogue Realisticness (Cultural Fitness)",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21254,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:29:02.302748",
      "updated_at": "2026-01-20T09:29:45",
      "id": 435,
      "is_enabled": 0,
      "weight": 1.0,
      "project_id": 50,
      "quality_dimension_id": 128,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nCan serve as reference model for learners and annotators. \nDemonstrates exemplary Korean writing that \nrepresents native-level quality.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "94136c83-8a78-440a-bb57-175fce6ebfc7",
        "source_timestamp": 1768901385000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Can serve as reference model for learners and annotators. \nDemonstrates exemplary Korean writing that \nrepresents native-level quality.",
      "code_execution_enabled": null,
      "name": "Golden Response Quality",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21253,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:29:02.297711",
      "updated_at": "2026-01-20T09:29:25",
      "id": 434,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 50,
      "quality_dimension_id": 125,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the spelling, use of comma, puctuation, etc..\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "43de1789-2001-44a0-a402-d6e3c52fde56",
        "source_timestamp": 1768901365000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the spelling, use of comma, puctuation, etc..",
      "code_execution_enabled": null,
      "name": "Orthography & Punctuation",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21252,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:29:02.296289",
      "updated_at": "2026-01-20T09:29:20",
      "id": 433,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 50,
      "quality_dimension_id": 127,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the use of particles (eun-neon-iee-ga), verb conjugation, subject-predicate agreement, and natural word order.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "3885e508-1d55-4993-9238-4424f27f52ee",
        "source_timestamp": 1768901360000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the use of particles (eun-neon-iee-ga), verb conjugation, subject-predicate agreement, and natural word order.",
      "code_execution_enabled": null,
      "name": "Korean Grammar and Syntax",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21251,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:29:02.293285",
      "updated_at": "2026-01-20T09:29:17",
      "id": 432,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 50,
      "quality_dimension_id": 124,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates sentence structure and the choice of vocabulary per context, technical term handling, and proper word order.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "88290592-8616-4292-ab49-1ced1597cb4b",
        "source_timestamp": 1768901357000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates sentence structure and the choice of vocabulary per context, technical term handling, and proper word order.",
      "code_execution_enabled": null,
      "name": "Sentence Structure (Word Order) & Vocab Choice",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21250,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:23:18.302830",
      "updated_at": "2026-01-20T09:25:22",
      "id": 431,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 49,
      "quality_dimension_id": 123,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the choice of vocabulary (Wago, Kango, loanwords) per context, technical term handling, and proper Kanji use.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "eb028678-94ba-44db-ab33-d18f531a9f73",
        "source_timestamp": 1768901122000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the choice of vocabulary (Wago, Kango, loanwords) per context, technical term handling, and proper Kanji use.",
      "code_execution_enabled": null,
      "name": "Vocabulary Selection & Kanji",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21249,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:23:18.287168",
      "updated_at": "2026-01-20T09:25:18",
      "id": 430,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 49,
      "quality_dimension_id": 120,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the use of Kanji, Hiragana, and Katakana, okurigana, typos, and the presence of character corruption.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "272565b6-7013-4302-b498-11e10ff1b425",
        "source_timestamp": 1768901118000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the use of Kanji, Hiragana, and Katakana, okurigana, typos, and the presence of character corruption.",
      "code_execution_enabled": null,
      "name": "Orthography (Notation & Spelling)",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21248,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:23:18.284345",
      "updated_at": "2026-01-20T09:25:12",
      "id": 429,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 49,
      "quality_dimension_id": 122,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates adherence to constraints like \"No Katakana,\" \"Legal style,\" or \"Use a specific dialect\".\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "463bef9b-c8d3-47e4-8812-7df995cc1905",
        "source_timestamp": 1768901112000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates adherence to constraints like \"No Katakana,\" \"Legal style,\" or \"Use a specific dialect\".",
      "code_execution_enabled": null,
      "name": "Compliance with Instructions",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21247,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:23:18.276333",
      "updated_at": "2026-01-20T09:25:09",
      "id": 428,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 49,
      "quality_dimension_id": 121,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the use of particles (te-ni-wo-ha), verb conjugation, subject-predicate agreement, and natural word order.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "bb1d2075-ee75-4ba0-92ee-7c178274aa49",
        "source_timestamp": 1768901109000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the use of particles (te-ni-wo-ha), verb conjugation, subject-predicate agreement, and natural word order.",
      "code_execution_enabled": null,
      "name": "Japanese Grammar and Syntax",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21246,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:23:18.273419",
      "updated_at": "2026-01-20T09:23:34",
      "id": 427,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 49,
      "quality_dimension_id": 119,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates the consistency of honourifics, reproduction of dialects, and consideration of Japanese cultural background.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "c49131b3-8926-42b8-b90d-dfa1f765dcb2",
        "source_timestamp": 1768901014000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates the consistency of honourifics, reproduction of dialects, and consideration of Japanese cultural background.",
      "code_execution_enabled": null,
      "name": "Honourifics & Cultural Fitness",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21245,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:21:43.911165",
      "updated_at": "2026-01-20T09:22:07",
      "id": 426,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 48,
      "quality_dimension_id": 118,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nWhether sentence construction reflects native, human-like word order and phrasing, rather than literal translations or syntactic patterns borrowed from English or other languages. Whether word choices are contextually appropriate, modern, and natural for the language, avoiding unnatural synonyms, literal translations, or excessively formal, archaic, or literary expressions/vocabulary/structure unless justified by the task.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "76f59078-a9c6-439c-b4e7-27550bf7a59f",
        "source_timestamp": 1768900927000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether sentence construction reflects native, human-like word order and phrasing, rather than literal translations or syntactic patterns borrowed from English or other languages. Whether word choices are contextually appropriate, modern, and natural for the language, avoiding unnatural synonyms, literal translations, or excessively formal, archaic, or literary expressions/vocabulary/structure unless justified by the task.",
      "code_execution_enabled": null,
      "name": "Natural Sentence Structure & Word Order",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21244,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:21:43.901881",
      "updated_at": "2026-01-20T09:22:04",
      "id": 425,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 48,
      "quality_dimension_id": 116,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nWhether the language appears human-written and avoids common LLM artifacts, such as repetitive phrasing, templated sentence openings, unnatural symmetry, or excessive explicitness. The text should exhibit variation in structure, natural emphasis, and pragmatic economy consistent with human authorship, but without seeming sloppy.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "6875ba81-dc92-48fb-929a-5e92f546d015",
        "source_timestamp": 1768900924000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether the language appears human-written and avoids common LLM artifacts, such as repetitive phrasing, templated sentence openings, unnatural symmetry, or excessive explicitness. The text should exhibit variation in structure, natural emphasis, and pragmatic economy consistent with human authorship, but without seeming sloppy.",
      "code_execution_enabled": null,
      "name": "Human-Likeness vs LLM Artifacts",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21243,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:21:43.899870",
      "updated_at": "2026-01-20T09:22:01",
      "id": 424,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 48,
      "quality_dimension_id": 117,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nVariant and forms of portuguese other than brazilian should be avoided (e.g. autocarro, comboio, casa de banho, telem�vel, bomba de combust�vel instead of posto de combust�vel, rebu�ado, pequeno-almo�o, rapariga, bicha instead of fila, sumo, frigor�fico instead of geladeira, etc).\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "ad69ccf2-843d-4e04-8d1f-daaefb2d6b33",
        "source_timestamp": 1768900921000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Variant and forms of portuguese other than brazilian should be avoided (e.g. autocarro, comboio, casa de banho, telem�vel, bomba de combust�vel instead of posto de combust�vel, rebu�ado, pequeno-almo�o, rapariga, bicha instead of fila, sumo, frigor�fico instead of geladeira, etc).",
      "code_execution_enabled": null,
      "name": "Brazilian Portuguese Correctness",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21242,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:21:43.890216",
      "updated_at": "2026-01-20T09:21:58",
      "id": 423,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 48,
      "quality_dimension_id": 114,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nWhether the content consistently uses the required standard language variant / regional specificities for the language, and avoids mixing regional specificities, informal speech (e.g., �t�, �pra�, �a gente�), or regionally incorrect forms unless explicitly required by the task.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "acd56476-4180-4ab8-bec5-de0387560e12",
        "source_timestamp": 1768900918000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether the content consistently uses the required standard language variant / regional specificities for the language, and avoids mixing regional specificities, informal speech (e.g., �t�, �pra�, �a gente�), or regionally incorrect forms unless explicitly required by the task.",
      "code_execution_enabled": null,
      "name": "Language Variant & Register Correctness",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21241,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:21:43.887220",
      "updated_at": "2026-01-20T09:21:56",
      "id": 422,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 48,
      "quality_dimension_id": 115,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nWhether the response avoids high-impact errors that are particularly damaging or unacceptable in this language, even if the general meaning remains understandable. Text must follow the core grammatical and morphological rules of the language (e.g., use of correct graphic accentuation, verb conjugation, nominal and verbal agreement, appropriate use of pronouns and prepositions, correct verb�preposition regency, and syntactic structures), without errors caused by English-driven structure or simplification. For example, avoid mixing the use of a/�, hyphen, c/�, s/z or similar. (E.g. avoid using sector, facto, director, acad�mico, fen�meno, econ�mico, contactar, direccionar, baptizar, bem vindo, etc).\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "33f46b94-0ca3-4692-8463-13326175c484",
        "source_timestamp": 1768900916000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether the response avoids high-impact errors that are particularly damaging or unacceptable in this language, even if the general meaning remains understandable. Text must follow the core grammatical and morphological rules of the language (e.g., use of correct graphic accentuation, verb conjugation, nominal and verbal agreement, appropriate use of pronouns and prepositions, correct verb�preposition regency, and syntactic structures), without errors caused by English-driven structure or simplification. For example, avoid mixing the use of a/�, hyphen, c/�, s/z or similar. (E.g. avoid using sector, facto, director, acad�mico, fen�meno, econ�mico, contactar, direccionar, baptizar, bem vindo, etc).",
      "code_execution_enabled": null,
      "name": "Sensitivity to Critical Portuguese Errors",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21240,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:14:51.859360",
      "updated_at": "2026-01-20T09:15:24",
      "id": 421,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 113,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nPosition of subject, verb and nouns. The main verb is always in the second position.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "d89604a5-1406-4546-b045-1b2a5549e8cb",
        "source_timestamp": 1768900524000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Position of subject, verb and nouns. The main verb is always in the second position.",
      "code_execution_enabled": null,
      "name": "Sentence Structure",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21239,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:14:51.840788",
      "updated_at": "2026-01-20T09:15:13",
      "id": 420,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 112,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nReferring to the right person is very important in German language usage. Its like ich (first person), du (second person), er/sie/es (Third person), wir (we), ihr (they/you all), Sie (you). Conjugation of the Verbs are dependent on this. Example: Conjugation for the verb Sehen (to see) is given below:\n\nich sehe \ndu siehst \ner/sie/es sieht \nwir sehen \nihr seht \nSie sehen\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "bbe582ee-8adb-4ef9-9ed5-5b3178ed16e2",
        "source_timestamp": 1768900513000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Referring to the right person is very important in German language usage. Its like ich (first person), du (second person), er/sie/es (Third person), wir (we), ihr (they/you all), Sie (you). Conjugation of the Verbs are dependent on this. Example: Conjugation for the verb Sehen (to see) is given below:\n\nich sehe \ndu siehst \ner/sie/es sieht \nwir sehen \nihr seht \nSie sehen",
      "code_execution_enabled": null,
      "name": "Grammatical Accuracy - Correct Reference and Conjugation",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21238,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:14:51.836027",
      "updated_at": "2026-01-20T09:15:08",
      "id": 419,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 111,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nDer, Die, Das are the 3 articles in German for the Nouns\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "43b6fa4d-ccac-4512-b73c-0e8d19f19ab7",
        "source_timestamp": 1768900508000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Der, Die, Das are the 3 articles in German for the Nouns",
      "code_execution_enabled": null,
      "name": "Correct Article",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21237,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:14:51.831874",
      "updated_at": "2026-01-20T09:15:05",
      "id": 418,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 110,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nOne has to use the correct cases in German, which are Nominativ, Akkusative, Dativ and Genetiv\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "0ad670fc-e0e6-4d39-8db6-c65545c420d2",
        "source_timestamp": 1768900505000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "One has to use the correct cases in German, which are Nominativ, Akkusative, Dativ and Genetiv",
      "code_execution_enabled": null,
      "name": "Grammatical Accuracy - Correct Cases",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21236,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:14:51.830459",
      "updated_at": "2026-01-20T09:15:03",
      "id": 417,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 109,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nNouns should start in capital letters and verbs in small letters\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "d10856ba-c25f-4099-858d-b81aac4385db",
        "source_timestamp": 1768900503000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Nouns should start in capital letters and verbs in small letters",
      "code_execution_enabled": null,
      "name": "Noun and Verb usage",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21235,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:10:59.204796",
      "updated_at": "2026-01-20T09:12:39",
      "id": 416,
      "is_enabled": 0,
      "weight": 1.0,
      "project_id": 45,
      "quality_dimension_id": 108,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nPosition of subject, verb and nouns. The main verb is always in the second position.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "c86de37e-2779-4036-be6a-bc13c45bb9ea",
        "source_timestamp": 1768900359000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Position of subject, verb and nouns. The main verb is always in the second position.",
      "code_execution_enabled": null,
      "name": "Sentence Structure",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21234,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:10:59.200792",
      "updated_at": "2026-01-20T09:12:42",
      "id": 415,
      "is_enabled": 0,
      "weight": 1.0,
      "project_id": 45,
      "quality_dimension_id": 105,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nDer, Die, Das are the 3 articles in German for the Nouns\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "64f2eac9-f467-4a26-ad69-8d2665182d23",
        "source_timestamp": 1768900362000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Der, Die, Das are the 3 articles in German for the Nouns",
      "code_execution_enabled": null,
      "name": "Correct Article",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21233,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:10:59.187240",
      "updated_at": "2026-01-20T09:12:44",
      "id": 414,
      "is_enabled": 0,
      "weight": 1.0,
      "project_id": 45,
      "quality_dimension_id": 106,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nNouns should start in capital letters and verbs in small letters\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "462ad899-cb48-4518-becb-a88ad43548b0",
        "source_timestamp": 1768900364000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Nouns should start in capital letters and verbs in small letters",
      "code_execution_enabled": null,
      "name": "Noun and Verb usage",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21232,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:10:59.180017",
      "updated_at": "2026-01-20T09:12:47",
      "id": 413,
      "is_enabled": 0,
      "weight": 1.0,
      "project_id": 45,
      "quality_dimension_id": 107,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nReferring to the right person is very important in German language usage. Its like ich (first person), du (second person), er/sie/es (Third person), wir (we), ihr (they/you all), Sie (you). Conjugation of the Verbs are dependent on this. Example: Conjugation for the verb Sehen (to see) is given below:\n\nich sehe \ndu siehst \ner/sie/es sieht \nwir sehen \nihr seht \nSie sehen\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "c362b613-3f3c-4f26-b521-7eea7a4d5a4a",
        "source_timestamp": 1768900367000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Referring to the right person is very important in German language usage. Its like ich (first person), du (second person), er/sie/es (Third person), wir (we), ihr (they/you all), Sie (you). Conjugation of the Verbs are dependent on this. Example: Conjugation for the verb Sehen (to see) is given below:\n\nich sehe \ndu siehst \ner/sie/es sieht \nwir sehen \nihr seht \nSie sehen",
      "code_execution_enabled": null,
      "name": "Grammatical Accuracy - Correct Reference and Conjugation",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21231,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:10:59.176340",
      "updated_at": "2026-01-20T09:13:12",
      "id": 412,
      "is_enabled": 0,
      "weight": 1.0,
      "project_id": 45,
      "quality_dimension_id": 104,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nOne has to use the correct cases in German, which are Nominativ, Akkusative, Dativ and Genetiv\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "6518dc70-813e-4792-b1aa-3845cf8f040d",
        "source_timestamp": 1768900392000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "One has to use the correct cases in German, which are Nominativ, Akkusative, Dativ and Genetiv",
      "code_execution_enabled": null,
      "name": "Grammatical Accuracy - Correct Cases",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21230,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:09:00.956840",
      "updated_at": "2026-01-20T09:09:22",
      "id": 411,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 45,
      "quality_dimension_id": 102,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nRichness and appropriateness of word choice and handling of technical terms.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "395ee819-e296-4919-9609-484a0eb4d946",
        "source_timestamp": 1768900162000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Richness and appropriateness of word choice and handling of technical terms.",
      "code_execution_enabled": null,
      "name": "Vocabulary",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21229,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:09:00.952907",
      "updated_at": "2026-01-20T09:09:16",
      "id": 410,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 45,
      "quality_dimension_id": 101,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAdequacy of tone of formality to the context of the conversation.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "b9297f1f-ff0c-425c-8cb0-36d64bf85b03",
        "source_timestamp": 1768900156000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Adequacy of tone of formality to the context of the conversation.",
      "code_execution_enabled": null,
      "name": "Tone",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21227,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:09:00.938606",
      "updated_at": "2026-01-20T09:09:18",
      "id": 409,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 45,
      "quality_dimension_id": 103,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nConsistency of Spanish expressions or idiomatic phrases in relation to the context of the conversation initiated by the user.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "a42b6f6c-35c4-4ec1-b9b7-900ca6cfa847",
        "source_timestamp": 1768900158000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Consistency of Spanish expressions or idiomatic phrases in relation to the context of the conversation initiated by the user.",
      "code_execution_enabled": null,
      "name": "Cultural Nuance",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21228,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:09:00.937640",
      "updated_at": "2026-01-20T09:09:14",
      "id": 408,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 45,
      "quality_dimension_id": 100,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nSentence structure, verb-agreement, gender, and number correctness. Ensures the text follows natural Spanish syntactic rules.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "74034f0f-ef51-4572-ad80-e0002b445800",
        "source_timestamp": 1768900154000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Sentence structure, verb-agreement, gender, and number correctness. Ensures the text follows natural Spanish syntactic rules.",
      "code_execution_enabled": null,
      "name": "Grammar & Spelling",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21226,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:07:13.493287",
      "updated_at": "2026-01-20T09:08:01",
      "id": 407,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 44,
      "quality_dimension_id": 98,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAvoids repetition (Il est important de noter que�). Varied sentence rhythm.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "d967c8aa-41c2-4cbf-a0b1-c16a890f132a",
        "source_timestamp": 1768900081000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Avoids repetition (Il est important de noter que�). Varied sentence rhythm.",
      "code_execution_enabled": null,
      "name": "Human Naturalness vs LLM Artifacts",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21225,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:07:13.492473",
      "updated_at": "2026-01-20T09:07:57",
      "id": 406,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 44,
      "quality_dimension_id": 99,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nNatural French order: Je lui ai parl� hier (not je parl� lui hier). Proper negation (ne�pas).\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "86055d60-c954-4637-bc52-e052db4c5b63",
        "source_timestamp": 1768900077000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Natural French order: Je lui ai parl� hier (not je parl� lui hier). Proper negation (ne�pas).",
      "code_execution_enabled": null,
      "name": "Sentence Structure & Word Order",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21224,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:07:13.485233",
      "updated_at": "2026-01-20T09:07:54",
      "id": 405,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 44,
      "quality_dimension_id": 97,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAvoids calques: faire sens ? avoir du sens; supporter ? soutenir.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "a9651ebc-4ea0-4f93-9897-fd604225ce0b",
        "source_timestamp": 1768900074000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Avoids calques: faire sens ? avoir du sens; supporter ? soutenir.",
      "code_execution_enabled": null,
      "name": "Cross-language Interference",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21223,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:07:13.470274",
      "updated_at": "2026-01-20T09:07:50",
      "id": 404,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 44,
      "quality_dimension_id": 96,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAvoids: ce/se, a/�, son/sont, ils manges.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "bf55b8be-e648-4a1d-aeba-5aa0740a4c6d",
        "source_timestamp": 1768900070000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Avoids: ce/se, a/�, son/sont, ils manges.",
      "code_execution_enabled": null,
      "name": "Sensitivity to Critical French Errors",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21222,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:07:13.456501",
      "updated_at": "2026-01-20T09:07:47",
      "id": 403,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 44,
      "quality_dimension_id": 94,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAccents (�), apostrophes (l�homme), spacing before : ; ? !.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "91bfabe8-5594-4d7a-96ed-58786e460330",
        "source_timestamp": 1768900067000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Accents (�), apostrophes (l�homme), spacing before : ; ? !.",
      "code_execution_enabled": null,
      "name": "Orthography & Punctuation",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21221,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:07:13.455844",
      "updated_at": "2026-01-20T09:07:44",
      "id": 402,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 44,
      "quality_dimension_id": 93,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nProper vous/tu, formulas (Je vous prie de, Cordialement).\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "92d3bc1c-ce66-4565-8871-64ab6b2999a5",
        "source_timestamp": 1768900064000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Proper vous/tu, formulas (Je vous prie de, Cordialement).",
      "code_execution_enabled": null,
      "name": "Pragmatic & Politeness Control",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21220,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:07:13.450670",
      "updated_at": "2026-01-20T09:07:41",
      "id": 401,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 44,
      "quality_dimension_id": 95,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nCorrect conjugation (il a fait), agreement (des id�es int�ressantes), tense usage, pronouns (dont, y, en).\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "48c5c9b0-96ad-4631-ab84-0e423d17d59f",
        "source_timestamp": 1768900061000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Correct conjugation (il a fait), agreement (des id�es int�ressantes), tense usage, pronouns (dont, y, en).",
      "code_execution_enabled": null,
      "name": "Grammatical & Morphological Accuracy",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21219,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:07:13.443667",
      "updated_at": "2026-01-20T09:07:34",
      "id": 400,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 44,
      "quality_dimension_id": 91,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nAppropriate vocabulary: tenir compte de, pertinent, s�engager. Avoids archaic (moult).\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "0bd1fba3-d88f-445d-8366-df66cf7f85e8",
        "source_timestamp": 1768900054000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Appropriate vocabulary: tenir compte de, pertinent, s�engager. Avoids archaic (moult).",
      "code_execution_enabled": null,
      "name": "Lexical Choice & Vocabulary",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21217,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T09:07:13.441508",
      "updated_at": "2026-01-20T09:07:37",
      "id": 399,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 44,
      "quality_dimension_id": 92,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nConsistent use of standard written French. Avoids slang (c�est ouf), SMS (pk), regional forms (chui), anglicisms (deadline).\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "18bd3f21-b53b-41a2-addd-dc5028fb080e",
        "source_timestamp": 1768900057000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Consistent use of standard written French. Avoids slang (c�est ouf), SMS (pk), regional forms (chui), anglicisms (deadline).",
      "code_execution_enabled": null,
      "name": "French Language Variant & Register Accuracy",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21218,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T03:06:35.142398",
      "updated_at": "2026-01-23T04:01:48",
      "id": 398,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 42,
      "quality_dimension_id": 90,
      "prompt": "INPUTS:\n- task: The complete task object\n- llm_judge_evaluations: LLM judge evaluations for model responses\n- human_judge_evaluations: Human judge evaluations for model responses\n{conversation}\n\nREQUIRED FORMAT (BOTH JUDGES MUST USE):\n\n[Grading Basis]:\n{\n  \"C1\": \"PASS\",\n  \"C2\": \"FAIL\",\n  \"C3\": \"PASS\",\n  \"C4\": \"PASS\",\n  \"C5\": \"PASS\"\n}\n\n[Score]: X point(s)\nWhere X is either 0 or 1\n\n[JSON]: {\"answer_score\": X}\nWhere X is either 0 or 1\n\n[Explanation]: [Brief explanation of which criteria failed and why. If no\ncriteria failed, state that explicitly.]\n\nGRADING SCALE (BOTH JUDGES MUST USE):\n- P > N/2 → 1 point (PASS)\n- P ≤ N/2 → 0 points (FAIL)\nWhere N = total number of criteria, P = number of criteria marked PASS\n\nEVALUATION CRITERIA:\n1. LLM Judge Format:\n   - Check [Grading Basis] format (JSON with C1, C2, etc.)\n   - Check [Score] format (\"X point(s)\")\n   - Check [JSON] format ({\"answer_score\": X})\n   - Check [Explanation] format\n   - Verify all sections present\n   - Verify grading scale application (P > N/2)\n\n2. Human Judge Format:\n   - Check same sections as LLM judge\n   - Verify format matches exactly\n   - Ensure all sections present\n   - Verify grading scale application (P > N/2)\n\n3. Format Consistency:\n   - Compare LLM and human judge formats\n   - Verify formats are identical\n   - Check section names are the same\n   - Verify JSON structures are the same\n   - Verify score formats are the same\n\n4. Criteria Evaluation Consistency:\n   - Verify both judges evaluate same criteria\n   - Check both use same grading scale (P > N/2)\n   - Ensure criteria IDs match (C1, C2, etc.)\n   - Verify both use same criteria array\n\nALLOWED PATTERNS:\n- Identical format between LLM and human judges\n- All required sections present in both\n- Consistent JSON structure\n- Same criteria evaluation approach\n- Same grading scale application (P > N/2)\n- Same criteria IDs used\n\nDISALLOWED PATTERNS:\n- Different formats between LLM and human judges\n- Missing sections in either judge\n- Inconsistent JSON structure\n- Different criteria evaluation\n- Different grading scale\n- Different criteria IDs\n\nFAILURE CONDITIONS:\n- FAIL if formats differ between LLM and human judges\n- FAIL if required sections are missing\n- FAIL if JSON structures are inconsistent\n- FAIL if criteria evaluation differs\n- FAIL if grading scale application differs\n- FAIL if criteria IDs differ\n\nDECISION OUTPUT FORMAT:\nPASS / FAIL\n\nReason Code: R8-[CODE]\nWhere CODE is one of:\n- FORMAT_MISMATCH: Formats differ between judges\n- MISSING_SECTIONS: Required sections missing\n- INCONSISTENT_JSON: JSON structures inconsistent\n- DIFFERENT_CRITERIA: Criteria evaluation differs\n- DIFFERENT_SCALE: Grading scale application differs\n- DIFFERENT_IDS: Criteria IDs differ\n\nJustification: [Short, objective statement]\nExample: \"FAIL - R8-FORMAT_MISMATCH: LLM judge uses [Grading Basis] format,\nbut human judge uses different format without [Grading Basis] section.\"\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "179282cd-47ad-4a43-b779-dc64dd5172a4",
        "source_timestamp": 1769140908000
      },
      "current_quality_dimension_version_id": 5177,
      "reviewer_type": "manual",
      "model": "gpt-5",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This rubric will verify that LLM judge and human judge use the SAME format for evaluation.",
      "code_execution_enabled": null,
      "name": "JUDGE FORMAT CONSISTENCY",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are the Judge Format Consistency Agent. Your responsibility is to verify\nthat LLM judge and human judge use the SAME format for evaluation. Both must\nuse [Grading Basis], [Score], [JSON], and [Explanation] sections with\nconsistent structure.\n",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21216,
      "tools": "",
      "sort_order": 7,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 3.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T03:04:38.309264",
      "updated_at": "2026-01-23T04:02:12",
      "id": 397,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 42,
      "quality_dimension_id": 89,
      "prompt": "INPUTS:\n- task: The complete task object\n- target_model_responses: List of target model responses (should be 4)\n- llm_judge_evaluations: LLM judge evaluations for each target response\n- breaking_rate_requirement: Minimum 75% breaking rate\n{conversation}\n\nBREAKING RATE REQUIREMENT:\n- At least 75% of target model responses MUST have score 0 (FAIL)\n- For 4 responses: minimum 3 must have score 0\n- For 3 responses: minimum 3 must have score 0 (100%)\n- For 2 responses: minimum 2 must have score 0 (100%)\n- This ensures task is actually doable but challenging\n\nGPT-5 RESPONSE REQUIREMENT:\n- GPT-5 response MUST be a PASS (score 1)\n- This validates that the task is actually doable\n- If GPT-5 fails, task may be too difficult or poorly designed\n\nEVALUATION CRITERIA:\n1. Response Identification:\n   - Identify all target model responses (Nemotron, Qwen, or target_model)\n   - Count total number of target responses (should be 4)\n   - Verify responses are from target models\n   - Exclude GPT-5 responses from breaking rate calculation\n\n2. Score Extraction:\n   - For each target response, extract LLM judge evaluation\n   - Extract score from [Score] or [JSON] section\n   - Score 0 = model broke (FAIL)\n   - Score 1 = model passed (PASS)\n   - Verify score format is correct\n   - Ensure scores are valid (0 or 1)\n\n3. Breaking Rate Calculation:\n   - Count number of responses with score 0\n   - Calculate percentage: (Number with score 0 / Total responses) × 100\n   - Requirement: ≥75% must have score 0\n   - For 4 responses: at least 3 must have score 0\n\n4. Requirement Verification:\n   - Check if breaking rate meets ≥75% requirement\n   - Verify calculation is correct\n   - Ensure all scores are valid (0 or 1)\n   - Verify GPT-5 response is PASS (if present)\n\nALLOWED PATTERNS:\n- Breaking rate ≥75% (at least 3 out of 4 responses with score 0)\n- Valid scores (0 or 1) for all responses\n- Proper score extraction from LLM judge evaluations\n- GPT-5 response with score 1 (PASS)\n\nDISALLOWED PATTERNS:\n- Breaking rate <75% (fewer than 3 out of 4 responses with score 0)\n- Invalid scores (not 0 or 1)\n- Missing LLM judge evaluations\n- Incorrect score extraction\n- GPT-5 response with score 0 (if present)\n\nFAILURE CONDITIONS:\n- FAIL if breaking rate <75%\n- FAIL if fewer than 3 out of 4 responses have score 0\n- FAIL if LLM judge evaluations are missing\n- FAIL if scores cannot be extracted\n- FAIL if scores are invalid (not 0 or 1)\n- FAIL if GPT-5 response has score 0 (task may be too difficult)\n\nDECISION OUTPUT FORMAT:\nPASS / FAIL\n\nReason Code: R7-[CODE]\nWhere CODE is one of:\n- LOW_BREAKING_RATE: Breaking rate <75%\n- MISSING_EVALUATIONS: LLM judge evaluations missing\n- INVALID_SCORES: Scores invalid or cannot be extracted\n- INSUFFICIENT_BREAKS: Fewer than required number of breaks\n- GPT5_FAILED: GPT-5 response failed (task may be too difficult)\n\nJustification: [Short, objective statement]\nExample: \"FAIL - R7-LOW_BREAKING_RATE: Only 2 out of 4 target model responses\nhave score 0 (50% breaking rate). Requirement is ≥75% (at least 3 out of 4).\"\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "f80632e6-370f-4bf4-b126-99e72f052ae0",
        "source_timestamp": 1769140932000
      },
      "current_quality_dimension_version_id": 5176,
      "reviewer_type": "manual",
      "model": "gpt-5",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This rubric verify that at least 75% of target model responses (Nemotron/Qwen) have a score of 0 (model broke) in LLM judge evaluation. ",
      "code_execution_enabled": null,
      "name": "TARGET MODEL BREAKING RATE ",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are the Model Breaking Rate Agent. Your responsibility is to verify that\nat least 75% of target model responses (Nemotron/Qwen) have a score of 0 (model\nbroke) in LLM judge evaluation. This ensures the task is actually testing\ncognitive inertia and is not too easy.\n",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21215,
      "tools": "",
      "sort_order": 6,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 3.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T03:02:40.721894",
      "updated_at": "2026-01-22T14:41:08",
      "id": 396,
      "is_enabled": 0,
      "weight": 1.0,
      "project_id": 42,
      "quality_dimension_id": 88,
      "prompt": "INPUTS:\n- task: The complete task object\n- judge_system_prompt: The judge system prompt text to be evaluated\n{conversation}\n\nREQUIRED GRADING SCALE FORMULA (CRITICAL):\nThe judge system prompt MUST use the following formula:\n- P > N/2 → 1 point (PASS)\n- P ≤ N/2 → 0 points (FAIL)\nWhere:\n- N = total number of criteria\n- P = number of criteria marked PASS\n\nWRONG FORMULAS (MUST REJECT):\n- P = N (all criteria must pass) - WRONG\n- P ≥ N/2 (greater than or equal) - WRONG, must be strictly greater than\n- P = N/2 (exactly half) - WRONG\n\nREQUIRED ELEMENTS:\n\n1. Role Definition (REQUIRED):\n   - Must include: \"meticulous, instruction-following grading teacher\" or\n     equivalent\n   - Must state: \"Your only responsibility is to evaluate a student's answer\n     solely against the provided Standard Answer criteria.\"\n   - Must include prohibitions: \"You must not: Infer intent, Reward partial\n     correctness, Excuse formatting or semantic errors, Apply leniency,\n     creativity, or interpretation\"\n\n2. Grading Scale Explanation (REQUIRED):\n   - Must explain: Two levels (0 points and 1 point)\n   - Must state: \"1 point (PASS): The student answer satisfies every single\n     criterion listed in the Standard Answer.\"\n   - Must state: \"0 points (FAIL): The student answer fails to satisfy any one\n     criterion, regardless of correctness elsewhere.\"\n   - Must state: \"All criteria are equally mandatory.\"\n   - Must state: \"There is no partial credit, no subjective judgment, and no\n     exceptions.\"\n   - MUST include P > N/2 formula (CRITICAL)\n   - Must state: \"Only the number of PASS criteria matters\"\n\n\n3. Output Format Specification (REQUIRED):\n   Must include all four sections in exact order:\n   - [Grading Basis]: JSON format with individual criteria PASS/FAIL\n     Example: {\"C1\": \"PASS\", \"C2\": \"FAIL\", \"C3\": \"PASS\"}\n   - [Score]: \"X point(s)\" where X is 0 or 1\n   - [JSON]: {\"answer_score\": X} where X is 0 or 1\n   - [Explanation]: Brief explanation of which criteria failed and why\n\n4. Examples (REQUIRED):\n   - Must include 2-3 examples\n   - Examples must demonstrate criteria-based evaluation\n   - Examples must show both PASS and FAIL cases\n   - Examples must use correct format\n   - Examples must demonstrate P > N/2 formula application\n\nEVALUATION CRITERIA:\n1. Role Definition:\n   - Must include \"meticulous, instruction-following grading teacher\" or\n     equivalent\n   - Role must be clearly defined\n   - Prohibitions must be stated\n\n2. Grading Scale Formula (CRITICAL):\n   - Must use: P > N/2 → 1 point (PASS)\n   - Must use: P ≤ N/2 → 0 points (FAIL)\n   - Must NOT use: P = N or P ≥ N/2\n   - Must state: \"Only the number of PASS criteria matters\"\n   - Formula must be clearly explained\n\n3. Output Format:\n   - Must include [Grading Basis] section with JSON format\n   - Must include [Score] section\n   - Must include [JSON] section with {\"answer_score\": X}\n   - Must include [Explanation] section\n   - Format must be clearly specified\n\n4. Examples:\n   - Must include 2-3 examples\n   - Examples must demonstrate criteria-based evaluation\n   - Examples must show both PASS and FAIL cases\n   - Examples must use correct format\n\n\nALLOWED PATTERNS:\n- Role definition with \"meticulous, instruction-following grading teacher\"\n- Correct formula: P > N/2 → 1 point, P ≤ N/2 → 0 points\n- Complete output format specification\n- 2-3 examples with PASS and FAIL cases\n- All required elements present\n\nDISALLOWED PATTERNS:\n- Missing role definition\n- Wrong formula: P = N or P ≥ N/2\n- Missing output format sections\n- Missing or insufficient examples\n- Formula not clearly explained\n\nFAILURE CONDITIONS:\n- FAIL if role definition is missing\n- FAIL if grading scale uses wrong formula (P = N or P ≥ N/2)\n- FAIL if output format sections are missing\n- FAIL if examples are missing or insufficient\n- FAIL if formula is not clearly explained\n\nDECISION OUTPUT FORMAT:\nPASS / FAIL\n\nReason Code: R6-[CODE]\nWhere CODE is one of:\n- MISSING_ROLE: Role definition missing\n- WRONG_FORMULA: Incorrect grading formula (P = N or P ≥ N/2)\n- MISSING_FORMAT: Output format sections missing\n- MISSING_EXAMPLES: Examples missing or insufficient\n- FORMULA_NOT_EXPLAINED: Formula not clearly explained\n\nJustification: [Short, objective statement]\nExample: \"FAIL - R6-WRONG_FORMULA: Judge system prompt uses P = N (all\ncriteria must pass) instead of correct formula P > N/2.\"\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "5d7f6e65-c61b-4144-a3a1-6a2f2aa48776",
        "source_timestamp": 1769092868000
      },
      "current_quality_dimension_version_id": 5132,
      "reviewer_type": "manual",
      "model": "gpt-5",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This rubric will verify that the judge_system_prompt follows all guidelines.",
      "code_execution_enabled": null,
      "name": "JUDGE SYSTEM PROMPT GUIDELINES COMPLIANCE",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are the Judge System Prompt Agent. Your responsibility is to verify that\nthe judge_system_prompt follows all guidelines. It must include role\ndefinition, correct grading scale (P > N/2 → 1 point, P ≤ N/2 → 0 points),\noutput format, and examples.\n",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21214,
      "tools": "",
      "sort_order": 8,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 3.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T02:59:38.341683",
      "updated_at": "2026-01-23T20:21:30",
      "id": 395,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 42,
      "quality_dimension_id": 87,
      "prompt": "INPUTS:\n- task: The complete task object containing all task components\n- prompt: The user prompt text to be evaluated\n- response_reference: The response reference with criteria array\n- task_type: The task type classification (QC, ITF, CC, CCF, DIA, II, MIM, CA)\n{conversation}\n\nGLOBAL RULE - DO NOT INFER:\n\nDO NOT infer, assume, or semantically expand prompt requirements.\nOnly exact textual matches or explicitly stated equivalents in the prompt\nare allowed. If a requirement is not clearly and directly present in the\nprompt text, it MUST be treated as NOT FOUND. Semantic inference, common-sense\nexpansion, or assumed intent is NOT allowed. This rule applies to ALL\nverification steps in this rubric.\n\nEVALUATION CRITERIA:\n\n1. Prompt Constraint Verification:\n   - Verify that ALL constraints in the prompt are explicit and unambiguous\n   - Check that prompt does not contain constraints that cannot be verified\n   - Ensure prompt constraints are testable and measurable\n\n2. Criteria Derivation from Prompt (PRIMARY VERIFICATION METHOD):\n   - For EACH criterion in response_reference, check if it was mentioned in the prompt\n   - Verify that EVERY requirement/constraint in each criterion appears in the prompt\n   - Check that each criterion can be traced back to explicit prompt text\n   - Ensure no criteria introduce requirements not stated in prompt\n   - Verify criteria do not expand or interpret prompt beyond explicit text\n   - Check that criteria match prompt requirements exactly (no additions)\n   - If a criterion contains a requirement NOT found in the prompt, it is an IMAGINARY CONSTRAINT\n\n3. Golden Answer Prohibition:\n   - Verify that criteria do NOT provide or reference golden answers\n   - Check that criteria do not specify what the \"correct\" answer should be\n   - Ensure criteria evaluate compliance, not correctness of content\n   - Verify criteria do not include expected answers or solutions\n   - Check that criteria focus on constraint compliance, not answer quality\n\n EXCEPTIONS FOR SPECIFIC TASK TYPES (INHERENT TO TASK TYPE):\n   - QC (Question Correction): Criteria may reference correct answers as this is\n     INHERENT to QC task type. QC tasks require identifying flaws and explaining\n     why options are wrong, which inherently requires knowing the correct answer\n     to verify the explanation. This is allowed even if not explicitly stated in\n     the prompt, as it is part of the task type definition.\n   - DIA (Deliberately Incorrect Answers): Criteria may reference which answers\n     should be correct/incorrect as this is INHERENT to DIA task type. DIA tasks\n     require verifying a specific ratio of correct/incorrect answers, which\n     inherently requires knowing which answers are correct/incorrect. This is\n     allowed even if not explicitly stated in the prompt, as it is part of the\n     task type definition.\n   - For all other task types (ITF, CC, CCF, II, MIM, CA): Golden answer\n     prohibition applies strictly - no references to correct answers allowed.\n\n\n4. External Knowledge Prohibition:\n   - Verify that criteria do NOT require external knowledge beyond prompt\n   - Check that criteria do not assume domain-specific knowledge not in prompt\n   - Ensure criteria do not reference facts, data, or information not provided\n   - Verify criteria do not require verification against external sources\n   - Check that all evaluation can be done using only prompt and response\n\n5. Vague Language Prohibition:\n   - Verify that criteria do NOT use vague or subjective terms\n   - Check for prohibited vague words: \"coherent\", \"quality\", \"well-written\",\n     \"appropriate\", \"good\", \"proper\", \"suitable\", \"adequate\", \"reasonable\"\n   - Ensure all criteria use specific, measurable, objective language\n   - Verify criteria use quantifiable terms (exact counts, specific formats)\n   - Check that criteria are testable without subjective judgment\n\n6. Duplication Check:\n   - Verify that criteria do NOT contain duplications\n   - Check that no criterion repeats the same requirement as another\n   - Ensure each criterion evaluates a distinct aspect\n   - Verify criteria are not redundant or overlapping\n   - Check that all criteria are necessary and non-repetitive\n\nTASK TYPE INHERENT CONSTRAINTS (for reference):\n\nQC (Question Correction):\nINHERENT (allowed in criteria even if NOT in prompt):\n- Stating that none of the provided options are correct (or equivalent phrases)\n- Identifying flaws in the question\n- Rejecting the premise of the question (if the question itself is flawed)\n- Avoiding selecting, endorsing, or modifying any of the options (A, B, C, D, etc.)\n- Explaining why options are wrong\n- Referencing correct answers (needed to verify explanation of why options are wrong)\n\nNOT INHERENT (must be explicit in prompt):\n- Specific calculation methods\n- Answer formats (unless explicit)\n- Additional explanations beyond identifying flaws and stating options are incorrect\n\nNOTE: QC prompts typically contain NO explicit instructions - they are just questions\nwith incorrect options. All QC inherent constraints are allowed in criteria even\nthough they are not mentioned in the prompt, as they are fundamental to the QC\ntask type definition.\n\nITF (Intentional Textual Flaws):\nINHERENT: Including errors is INHERENT to ITF task type.\nNOT INHERENT: Error count/type MUST be explicit in prompt. Factual accuracy\nrequirement is NOT inherent (unless explicit).\n\nCC (Code Without Comments):\nINHERENT: Code being functional is INHERENT to CC task type.\nNOT INHERENT: \"No comments\" MUST be explicit in prompt. Variable naming\nconstraints MUST be explicit. Code language specification MUST be explicit.\n\nCCF (Counter-Conventional Formatting):\nINHERENT: Avoiding structure when instructed is INHERENT to CCF task type.\nNOT INHERENT: Format restrictions MUST be explicit in prompt. Specific\nformatting elements to avoid MUST be explicit.\n\nDIA (Deliberately Incorrect Answers):\nINHERENT: Some answers being incorrect is INHERENT to DIA task type.\nNOT INHERENT: Ratio MUST be explicit in prompt. Number of questions MUST be\nexplicit. Which questions to answer incorrectly is NOT inherent.\nReferencing correct/incorrect answers in criteria is INHERENT (needed to verify ratio).\n\nII (Instructional Induction):\nINHERENT: Simple answer without template application is INHERENT to II task type.\nNOT INHERENT: Specific answer format, calculation methods (unless explicit).\n\nMIM (Mid-Turn Instruction Modification):\nINHERENT: Following final instruction only is INHERENT to MIM task type.\nNOT INHERENT: Specific instruction content, answer format (unless explicit).\n\nCA (Counterfactual Answering):\nINHERENT: Using counterfactual without correction is INHERENT to CA task type.\nNOT INHERENT: Instruction to use text exclusively MUST be explicit. \"Do not\ncorrect\" MUST be explicit.\n\nVERIFICATION PROCESS (CRITERION-BY-CRITERION CHECK):\n\nThe primary method for finding imaginary constraints is to check EACH criterion\nin the response_reference against the prompt to see if it was mentioned.\n\nSTEP 1: Extract ALL Constraints from Prompt\n- List every constraint, requirement, or specification in the prompt\n- Note exact wording of each constraint\n- Document all explicit requirements\n- Create complete inventory of prompt constraints\n- This inventory will be used to verify each criterion\n\nSTEP 2: Extract ALL Criteria from Response Reference\n- List each criterion (C1, C2, C3, etc.) from response_reference\n- Note exact text of each criterion\n- Extract all requirements/constraints mentioned in each criterion\n- Create complete inventory of criteria requirements\n\nSTEP 3: Check EACH Criterion Against Prompt (CRITICAL STEP)\n- For EACH criterion (C1, C2, C3, etc.), perform the following:\n  a) Read the criterion text carefully\n  b) Identify ALL requirements/constraints mentioned in this criterion\n  c) For EACH requirement in the criterion:\n     i) First, check if requirement is found in the prompt as exact textual match\n        or explicitly stated paraphrase (NOT semantic inference)\n     ii) If found in prompt, mark as VERIFIED (explicit in prompt)\n     iii) If NOT found in prompt, check if requirement is INHERENT to task type\n          (see TASK TYPE INHERENT CONSTRAINTS section)\n     iv) If requirement is INHERENT to task type, mark as VERIFIED (inherent)\n     v) If requirement is neither in prompt nor inherent to task type, mark as\n        IMAGINARY CONSTRAINT\n  d) DO NOT infer equivalence - only accept exact matches or explicitly stated\n     paraphrases that are directly present in the prompt text\n  e) For QC tasks: Remember that prompts typically have NO explicit instructions.\n     All QC inherent constraints (stating options incorrect, identifying flaws,\n     rejecting premise, avoiding selection) are allowed even if not in prompt.\n  f) Document which requirements are verified (explicit vs inherent) and which\n     are imaginary\n- If ANY requirement in ANY criterion is neither in prompt nor inherent to task\n  type, the criterion contains an imaginary constraint and this rubric FAILS\n- Continue checking all criteria systematically, one by one\n\nSTEP 4: Check for Golden Answers in Criteria\n- Review each criterion for references to \"correct\" answers\n- Check if criteria specify expected content or solutions\n- Verify criteria focus on compliance, not correctness\n- Flag any criteria that provide or reference golden answers\n- For QC tasks: Allow correct answer references as INHERENT to task type (needed\n  to verify explanation of why options are wrong)\n- For DIA tasks: Allow correct/incorrect answer references as INHERENT to task\n  type (needed to verify the specified ratio)\n- For all other task types: Flag any criteria that provide or reference golden answers\n\n\nSTEP 5: Check for External Knowledge Requirements\n- Review each criterion for external knowledge assumptions\n- Check if criteria require domain knowledge not in prompt\n- Verify all evaluation can use only prompt and response\n- Flag any criteria requiring external verification\n\nSTEP 6: Check for Vague Language\n- Scan all criteria for prohibited vague words\n- Check for: \"coherent\", \"quality\", \"well-written\", \"appropriate\", \"good\",\n  \"proper\", \"suitable\", \"adequate\", \"reasonable\"\n- Verify all language is specific and measurable\n- Flag any vague or subjective terms\n\nSTEP 7: Check for Duplications\n- Compare all criteria against each other\n- Identify any redundant or overlapping requirements\n- Verify each criterion evaluates distinct aspect\n- Flag any duplications\n\nSTEP 8: Verify Prompt Constraints Are Explicit\n- Re-read prompt to ensure all constraints are explicit\n- Check that prompt does not use vague language\n- Verify prompt constraints are testable\n- Ensure prompt does not rely on external knowledge\n\nSTEP 9: Cross-Reference with Task Type Inherent Constraints (CRITICAL FOR QC TASKS)\n- For constraints not explicit in prompt, check if inherent to task type\n- Verify inherent constraints match task type definitions exactly\n- For QC tasks: Check if criteria requirements match QC inherent constraints:\n  * Stating that none of options are correct - INHERENT (allowed)\n  * Identifying flaws in question - INHERENT (allowed)\n  * Rejecting premise of question - INHERENT (allowed)\n  * Avoiding selecting/endorsing/modifying options - INHERENT (allowed)\n  * Explaining why options are wrong - INHERENT (allowed)\n  * Referencing correct answers - INHERENT (allowed)\n- For DIA tasks: Check if criteria reference correct/incorrect answers - INHERENT\n- Ensure no false claims of inherent constraints\n- Document inherent vs explicit constraints\n- Remember: QC prompts may have NO instructions - all QC inherent constraints\n  are valid in criteria even if not mentioned in prompt\n\nSTEP 10: Final Verification\n- Review all criterion-by-criterion check results from STEP 3\n- Verify no imaginary constraints were found in any criterion\n- Confirm ALL requirements in ALL criteria were either:\n  * Found in the prompt (explicit), OR\n  * Inherent to the task type (per definitions)\n- For QC tasks: Verify that criteria about stating options incorrect, identifying\n  flaws, rejecting premise, and avoiding selection are properly recognized as\n  inherent (even if not in prompt)\n- If any requirement is neither in prompt nor inherent to task type, this rubric FAILS\n- Generate final PASS/FAIL decision based on criterion-by-criterion verification\n\nALLOWED PATTERNS:\n- Criteria derived directly from explicit prompt text\n- Specific, measurable, objective language in criteria\n- Quantifiable requirements (exact counts, specific formats)\n- Testable conditions without subjective judgment\n- Distinct, non-redundant criteria\n- Constraints inherent to task type (per definitions)\n- Criteria that evaluate compliance, not correctness\n- For QC tasks: All QC inherent constraints are allowed even if not in prompt:\n  * Stating that none of options are correct\n  * Identifying flaws in question\n  * Rejecting premise of question\n  * Avoiding selecting/endorsing/modifying options\n  * Explaining why options are wrong\n  * Referencing correct answers\n- For DIA tasks: Correct/incorrect answer references (INHERENT to task type)\n\n\nDISALLOWED PATTERNS:\n- Criteria not derived from prompt AND not inherent to task type\n- Golden answers or expected solutions in criteria (EXCEPT for QC/DIA as inherent\n  to task type)\n- External knowledge requirements in criteria\n- Duplicate or redundant criteria\n- Constraints in prompt that cannot be verified\n- Subjective evaluation requirements\n- Assumptions or inferences beyond prompt text\n- Correct answer references in task types other than QC/DIA\n- For QC tasks: Additional requirements beyond QC inherent constraints that are\n  neither in prompt nor inherent (e.g., requiring extra explanations not\n  inherent to QC task type)\n\nFAILURE CONDITIONS:\n- FAIL if ANY requirement in ANY criterion is neither in prompt nor inherent to\n  task type (imaginary constraint)\n- FAIL if checking each criterion against prompt and task type inherent constraints\n  reveals requirements that are neither explicit nor inherent\n- FAIL if criteria contain golden answers or expected solutions (EXCEPT for QC/DIA\n  tasks where it is INHERENT to task type)\n- FAIL if criteria in non-QC/DIA tasks reference correct answers or golden solutions\n- FAIL if criteria require external knowledge not in prompt\n- FAIL if criteria use vague or subjective language\n- FAIL if criteria contain duplications\n- FAIL if prompt contains untestable or vague constraints\n- FAIL if prompt relies on external knowledge or assumptions\n- FAIL if QC criteria claim inherent constraints that don't match QC inherent\n  definitions (e.g., requiring extra explanations not inherent to QC)\n\nFAILURE PRIORITY RULE:\nIf ANY single criterion fails under STEP 3 (criterion-by-criterion check),\nthe agent MUST immediately mark the rubric as FAIL without weighing other steps.\nDo not balance failures against other criteria. Do not consider other verification\nsteps if STEP 3 reveals an imaginary constraint. The failure is immediate and\nabsolute.\n\nPRIMARY FAILURE CONDITION:\nIf checking each criterion in response_reference against the prompt AND task type\ninherent constraints reveals ANY requirement that was neither mentioned in the\nprompt nor inherent to the task type, this rubric FAILS immediately.\n\nFor QC tasks: Remember that prompts may have NO instructions. Criteria about\nstating options incorrect, identifying flaws, rejecting premise, and avoiding\nselection are ALLOWED as inherent, even if not in prompt.\n\nOUTPUT STRICTNESS RULE:\nThe agent must output ONLY the decision format specified below.\nProvide comprehensive, structured feedback to help trainers understand issues\nand fix them. All feedback must be objective, specific, and actionable.\n\nDECISION OUTPUT FORMAT:\n\nPASS / FAIL\n\nReason Code: R9-[CODE]\nWhere CODE is one of:\n- IMAGINARY_CONSTRAINT: Requirement in criterion not found in prompt or task type\n- PROMPT_IMAGINARY: Prompt contains imaginary or untestable constraints\n- CRITERIA_NOT_DERIVED: Criteria not derived from prompt or task type\n- GOLDEN_ANSWER: Criteria contain golden answers or expected solutions (non-QC/DIA)\n- EXTERNAL_KNOWLEDGE: Criteria require external knowledge not in prompt\n- VAGUE_LANGUAGE: Criteria use vague or subjective language\n- DUPLICATION: Criteria contain duplications or redundancies\n- PROMPT_VAGUE: Prompt uses vague or untestable language\n\nSTRUCTURED FEEDBACK (REQUIRED FOR FAIL):\n\n1. Summary:\n   [One-sentence summary of the issue]\n\n2. What Was Found:\n   - Criterion(s) with issue: [List specific criteria IDs, e.g., C1, C3]\n   - Requirement(s) in question: [Quote exact requirement text from criteria]\n   - Prompt content checked: [Quote relevant prompt text, or state \"No explicit\n     instructions found in prompt\" for QC tasks]\n   - Task type: [QC, ITF, CC, CCF, DIA, II, MIM, CA]\n   - Inherent constraint check: [State whether requirement matches task type\n     inherent constraints]\n\n3. Why This Is An Issue:\n   - [Explain why the requirement is not allowed]\n   - [If not in prompt: Explain why it's not found in prompt text]\n   - [If not inherent: Explain why it doesn't match task type inherent constraints]\n   - [Reference relevant section: e.g., \"Per TASK TYPE INHERENT CONSTRAINTS,\n     QC tasks allow X, Y, Z but not this requirement\"]\n\n4. How To Fix:\n   - [Specific, actionable steps to resolve the issue]\n   - [If imaginary constraint: \"Remove requirement X from criterion C3, OR add\n     explicit instruction X to the prompt\"]\n   - [If vague language: \"Replace 'well-written' with specific requirement like\n     'contains exactly 3 sentences'\"]\n   - [If QC task: \"For QC tasks, only these inherent constraints are allowed:\n     [list]. This requirement is not in that list.\"]\n\n5. Examples:\n   - Current (incorrect): [Quote the problematic criterion text]\n   - Correct approach: [Show what the criterion should look like, or reference\n     what's allowed]\n\nFEEDBACK EXAMPLES:\n\nExample 1 - Imaginary Constraint:\nFAIL - R9-IMAGINARY_CONSTRAINT\n\n1. Summary:\nCriterion C3 contains a requirement (\"factual accuracy\") that is neither\nexplicitly stated in the prompt nor inherent to the ITF task type.\n\n2. What Was Found:\n- Criterion with issue: C3\n- Requirement in question: \"Does the response maintain factual accuracy?\"\n- Prompt content checked: The prompt states \"Answer in exactly three sentences.\n  First sentence: 1 typo. Second sentence: 2 typos. Third sentence: 3 typos.\"\n  No mention of factual accuracy requirement.\n- Task type: ITF\n- Inherent constraint check: ITF task type does NOT have factual accuracy as\n  an inherent constraint. ITF only has \"including errors\" as inherent, but\n  error count/type must be explicit (which it is).\n\n3. Why This Is An Issue:\nThe requirement \"factual accuracy\" is an imaginary constraint because:\n- It is not explicitly stated in the prompt text\n- It is not inherent to ITF task type (per TASK TYPE INHERENT CONSTRAINTS)\n- ITF tasks are about including errors, not maintaining factual accuracy\n- Adding this requirement would make evaluation subjective\n\n4. How To Fix:\n- Option 1: Remove \"factual accuracy\" requirement from C3\n- Option 2: If factual accuracy is truly needed, add explicit instruction to\n  prompt: \"Maintain factual accuracy while including the specified errors\"\n- Recommended: Remove the requirement, as ITF tasks focus on error inclusion,\n  not factual accuracy\n\n5. Examples:\n- Current (incorrect): \"Does the response maintain factual accuracy?\"\n- Correct approach: \"Does the response contain exactly 3 sentences with 1, 2,\n  and 3 typos respectively?\" (matches explicit prompt requirements)\n\nExample 2 - QC Task (Inherent Constraint):\nFAIL - R9-IMAGINARY_CONSTRAINT\n\n1. Summary:\nCriterion C4 contains a requirement (\"provide detailed mathematical explanation\")\nthat is neither in the prompt nor inherent to QC task type.\n\n2. What Was Found:\n- Criterion with issue: C4\n- Requirement in question: \"Does the response provide a detailed mathematical\n  explanation of the calculation?\"\n- Prompt content checked: Prompt is a question with options A-D. No explicit\n  instructions found (typical for QC tasks).\n- Task type: QC\n- Inherent constraint check: QC inherent constraints include: stating options\n  incorrect, identifying flaws, rejecting premise, avoiding selection, explaining\n  why options are wrong. \"Detailed mathematical explanation\" is NOT in the QC\n  inherent list - only \"explaining why options are wrong\" is inherent.\n\n3. Why This Is An Issue:\nThe requirement \"detailed mathematical explanation\" is an imaginary constraint:\n- Not in prompt (QC prompts typically have no instructions)\n- Not in QC inherent constraints - QC only requires explaining WHY options are\n  wrong, not providing detailed mathematical explanations\n- Per TASK TYPE INHERENT CONSTRAINTS: \"NOT INHERENT: Specific calculation\n  methods, answer formats (unless explicit)\"\n\n4. How To Fix:\n- Remove \"detailed mathematical explanation\" requirement from C4\n- Change to: \"Does the response explain why the options are wrong?\" (this is\n  inherent to QC)\n- OR if detailed explanation is truly needed, add explicit instruction to prompt\n  (though this is unusual for QC tasks)\n\n5. Examples:\n- Current (incorrect): \"Does the response provide a detailed mathematical\n  explanation of the calculation?\"\n- Correct approach: \"Does the response explain why the options A-D are\n  incorrect?\" (matches QC inherent constraint)\n\nExample 3 - Vague Language:\nFAIL - R9-VAGUE_LANGUAGE\n\n1. Summary:\nCriterion C2 uses vague, subjective language (\"well-written\") that cannot be\nobjectively evaluated.\n\n2. What Was Found:\n- Criterion with issue: C2\n- Requirement in question: \"Is the response well-written?\"\n- Prompt content checked: Prompt specifies \"Answer in exactly 3 sentences with\n  1, 2, and 3 typos respectively\"\n- Task type: ITF\n- Vague word detected: \"well-written\" (prohibited vague word per VAGUE LANGUAGE\n  PROHIBITION section)\n\n3. Why This Is An Issue:\n\"well-written\" is vague and subjective because:\n- Different evaluators may have different standards for \"well-written\"\n- It cannot be objectively measured or tested\n- It violates the VAGUE LANGUAGE PROHIBITION rule\n- Prohibited vague words include: \"coherent\", \"quality\", \"well-written\",\n  \"appropriate\", \"good\", \"proper\", \"suitable\", \"adequate\", \"reasonable\"\n\n4. How To Fix:\n- Replace \"well-written\" with specific, measurable requirements from the prompt\n- Use quantifiable terms: exact counts, specific formats, testable conditions\n- Base criterion on explicit prompt requirements: \"exactly 3 sentences\",\n  \"1 typo in first sentence\", etc.\n\n5. Examples:\n- Current (incorrect): \"Is the response well-written?\"\n- Correct approach: \"Does the response contain exactly 3 sentences?\" OR\n  \"Does the first sentence contain exactly 1 typo?\" (specific, measurable)\n\n\n\n\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "79288362-2907-4fc6-8352-ad57b1d192ce",
        "source_timestamp": 1769199690000
      },
      "current_quality_dimension_version_id": 5175,
      "reviewer_type": "manual",
      "model": "gpt-5",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This rubric will verify that the response_reference criteria contain NO imaginary constraints.",
      "code_execution_enabled": null,
      "name": "NO IMAGINARY CONSTRAINTS IN RESPONSE REFERENCE",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are the No Imaginary Constraints Agent. Your responsibility is to verify\nthat the response_reference criteria contain NO imaginary constraints. The\nverification process involves checking EACH criterion in the response_reference\nagainst the prompt to determine whether it was mentioned in the prompt OR is\ninherent to the task type. All constraints in criteria must be either:\n1. Explicitly mentioned in the prompt itself, OR\n2. Inherent to the task type definition (per TASK TYPE INHERENT CONSTRAINTS)\n\nIMPORTANT NOTE FOR QC TASKS:\nQC (Question Correction) prompts typically contain NO explicit instructions - they\nare just questions with incorrect options. For QC tasks, criteria about stating\noptions are incorrect, identifying flaws, rejecting premise, and avoiding selection\nare ALLOWED as inherent to the task type, even though they are not mentioned in\nthe prompt. This is a fundamental characteristic of QC tasks.",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21213,
      "tools": "",
      "sort_order": 5,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 2.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T02:56:51.279653",
      "updated_at": "2026-01-23T04:02:04",
      "id": 394,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 42,
      "quality_dimension_id": 86,
      "prompt": "INPUT FORMAT:\nYou will receive:\n- response_reference: The response reference text/criteria\n\nRESPONSE REFERENCE START\n{task_data[contents.cells[3]]}\nRESPONSE REFERENCE END\n\nEVALUATION TASK:\nVerify that response_reference contains a valid criteria array structure.\n\nVALID ARRAY REQUIREMENTS:\n1. Contains a JSON array of criterion objects\n2. Each object has \"id\" field (C1, C2, C3...) and corresponding \"criteriaN\" field\n3. Array may appear inside markdown code blocks (```json ... ```) - this is VALID\n4. Additional text before/after array is PERMITTED\n\nPARSING TOLERANCE:\n- Accept arrays inside markdown code fences (```json or ```)\n- Accept both compact and pretty-printed JSON\n- Accept minor whitespace/formatting variations\n- Sequential gaps in IDs are acceptable (C1, C3, C4 is valid)\n- Focus on structural presence, not strict JSON validation\n\nPASS CONDITIONS:\n- At least one criteria array structure is found\n- Array contains objects with \"id\" and \"criteria\" pattern\n\nFAIL CONDITIONS:\n- response_reference is empty or missing\n- NO array structure found anywhere (including inside code blocks)\n- Array exists but objects lack required \"id\" or \"criteria\" fields\n\nEvaluate structure presence ONLY. Ignore: content quality, language, alignment, scoring logic.\n\nFirst: Scan for array structure (including inside code blocks).\nThen: Check for required fields in array objects.\nThen: Determine status.\n\nOUTPUT FORMAT:\nR4 EVALUATION:\nSTATUS: [PASS/FAIL]\nARRAY FOUND: [YES/NO]\nLOCATION: [Direct/Inside code block/Not found]\nFIELDS VALID: [YES/NO/N/A]\nREASONING: [2 sentences max - what you found and why PASS/FAIL]\nVIOLATIONS: [If FAIL only - specific missing element]\nEND R4 EVALUATION ",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "43afcd1d-c276-4796-bbd0-3e091ad2143e",
        "source_timestamp": 1769140924000
      },
      "current_quality_dimension_version_id": 5174,
      "reviewer_type": "manual",
      "model": "gpt-5",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This rubirc will verify that the response_reference uses the NEW criteria array format as specified in by the client",
      "code_execution_enabled": null,
      "name": "RESPONSE REFERENCE FORMAT",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "YOUR ROLE:\nYou are a deterministic, rule-based evaluator. Your ONLY job is to verify whether the response_reference contains a valid criteria array format. You output BINARY PASS or FAIL only.\n\nYOUR TASK:\nVerify ONLY that response_reference contains a criteria array with proper structure. Additional text before or after the array is PERMITTED and should NOT cause FAIL.\n\n",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21212,
      "tools": "",
      "sort_order": 4,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 3.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T02:54:37.808314",
      "updated_at": "2026-01-23T04:02:00",
      "id": 393,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 42,
      "quality_dimension_id": 85,
      "prompt": "\nINPUT FORMAT:\nYou will receive:\n- prompt: The task prompt text\n- ideal_response: The ideal/golden response text\n- task_type: The task taxonomy (QC, ITF, CC, CCF, DIA, II, MIM, or CA)\n{conversation}\nEVALUATION CRITERIA (ONLY CHECK THESE):\n\n1. COUNTER-INTUITIVE CONSTRAINT COMPLIANCE (PRIMARY CHECK):\n   a) Does the ideal response demonstrate following the counter-intuitive instruction from the prompt?\n   b) For ITF tasks: Does response contain errors as specified? (Approximate count is acceptable - don't require exact match)\n   c) For CC tasks: Does code lack comments/minimal naming as specified? (Functional check is secondary)\n   d) For CCF tasks: Does response avoid specified formatting restrictions?\n   e) For DIA tasks: Does response have incorrect answers as specified? (Approximate ratio is acceptable)\n   f) For QC tasks: Does response identify flaws and reject incorrect options?\n   g) For II tasks: Does response provide simple answer without complex template?\n   h) For MIM tasks: Does response follow the final instruction, ignoring earlier ones?\n   i) For CA tasks: Does response use counterfactual information without correction?\n\n2. REASONABLE COMPLIANCE CHECK:\n   a) The response should reasonably demonstrate the counter-intuitive behavior.\n   b) Minor deviations or imperfections are acceptable if the core constraint is followed.\n   c) Do NOT fail for:\n      - Minor formatting issues\n      - Slight variations in error counts (if close to requirement)\n      - Meta-commentary (ignore this - not a failure reason)\n      - Quality issues (ignore this - not a failure reason)\n      - Minor completeness issues (ignore this - not a failure reason)\n\nOUTPUT FORMAT:\nYou MUST output in this exact format:\n\nR3 EVALUATION:\nSTATUS: [PASS/FAIL]\n\nCOMPLIANCE ANALYSIS:\n- Follows counter-intuitive constraint: [YES/NO]\n- Core requirement met: [YES/NO]\n\nDETAILED REASONING:\n[Explain:\n1. How the ideal response demonstrates (or fails to demonstrate) the counter-intuitive constraint\n2. Whether the core counter-intuitive behavior is present\n3. Any minor deviations (which are acceptable) vs major violations (which cause FAIL)\n]\n\nSPECIFIC VIOLATIONS (if FAIL):\n[List ONLY major violations that prevent the response from demonstrating the counter-intuitive constraint:\n- \"Core constraint not followed: [details]\"\n]\n\n END R3 EVALUATION:\n\nCRITICAL RULES:\n- You are a lenient evaluator focused ONLY on core counter-intuitive constraint compliance\n- If ideal response is missing or empty → FAIL\n- If ideal response does NOT demonstrate the counter-intuitive constraint at all → FAIL\n- Be LENIENT: Minor deviations, approximate counts, formatting issues, meta-commentary, or quality issues should NOT cause FAIL\n- Output PASS if the response reasonably demonstrates following the counter-intuitive constraint, even with minor imperfections\n- Only FAIL if the response completely fails to demonstrate the counter-intuitive behavior\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "d43e57d6-e440-4a30-a3df-3c0698af7e87",
        "source_timestamp": 1769140920000
      },
      "current_quality_dimension_version_id": 5173,
      "reviewer_type": "manual",
      "model": "gpt-5",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This rubirc will evaluatewhether the ideal response is correct, appropriate for the prompt, and demonstrates perfect compliance with the counter-intuitive instruction. ",
      "code_execution_enabled": null,
      "name": "IDEAL RESPONSE QUALITY",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are the Ideal Response Quality Agent (R3) for Inverse IFEval task validation.\n\nYOUR ROLE:\nYou are a deterministic, rule-based evaluator. Your ONLY job is to verify whether the ideal response demonstrates following the counter-intuitive instruction from the prompt. You output BINARY PASS or FAIL only.\n\nYOUR TASK:\nEvaluate ONLY whether the ideal response follows the counter-intuitive constraint specified in the prompt. Be lenient and focus on the core requirement - does the response demonstrate the counter-intuitive behavior?\n\n",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21211,
      "tools": "",
      "sort_order": 3,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 2.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T02:51:55.163027",
      "updated_at": "2026-01-23T04:01:57",
      "id": 392,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 42,
      "quality_dimension_id": 84,
      "prompt": "INPUT FORMAT:\nYou will receive:\n- prompt: The task prompt text\n- metadata: Task metadata that may contain length requirements (e.g., \"User Prompt Length: 50 - 100 words\")\n{metadata} {conversation}\n\n\nEVALUATION CRITERIA :\n\n1. LENGTH REQUIREMENT EXTRACTION:\n   a) Check if a prompt length requirement is specified in the task metadata.\n   b) Extract the requirement (e.g., \"50-100 words\", \"User Prompt Length: 50 - 100 words\").\n   c) If no requirement is specified, use very lenient default: 5-5000 words (only fail if clearly problematic).\n\n2. WORD COUNT CALCULATION:\n   a) Count all words in the prompt text using a reasonable method.\n   b) Word definition: Any sequence of alphanumeric characters separated by whitespace or punctuation.\n   c) Be lenient in counting - approximate counts are acceptable.\n   d) Do NOT be overly strict about formatting symbols or empty lines.\n\n3. COMPLIANCE CHECK:\n   a) If requirement is specified (e.g., \"50-100 words\"):\n      - Extract minimum and maximum values\n      - Allow reasonable tolerance (±10% or ±5 words, whichever is larger)\n      - Example: For \"50-100 words\", accept 45-110 words\n      - PASS if within range or close to range, FAIL only if clearly outside\n   b) If no requirement specified:\n      - Use very lenient default: 5-5000 words\n      - PASS if prompt has reasonable content (not empty, not extremely short, not extremely long)\n      - Only FAIL if clearly problematic (< 3 words or > 10000 words)\n\n4. EDGE CASES :\n   a) If prompt is empty or missing → FAIL\n   b) If prompt is extremely short (< 3 words) → FAIL (clearly incomplete)\n   c) If prompt is excessively long (> 10000 words) → FAIL (likely contains errors)\n   d) For all other cases, be LENIENT and PASS\n\n\nOUTPUT FORMAT:\nYou MUST output in this exact format:\n\n R2 EVALUATION :\nSTATUS: [PASS/FAIL]\n\nWORD COUNT ANALYSIS:\n- Actual word count: [number] (approximate)\n- Required range: [min-max words or \"Not specified, using lenient default 5-5000\"]\n- Within range (with tolerance): [YES/NO]\n\nDETAILED REASONING:\n[Explain:\n1. How you extracted/identified the length requirement\n2. How you counted the words (approximate count is acceptable)\n3. Whether the count falls within the required range (with tolerance applied)\n4. Why you are passing (lenient evaluation) or failing (clearly problematic)\n]\n\nSPECIFIC VIOLATION (if FAIL):\n[State exactly why it failed: \"Word count X is clearly outside reasonable range\" or \"Prompt is extremely short/long\"]\n\nEND R2 EVALUATION:\n\nCRITICAL RULES:\n- You are a LENIENT evaluator - default to PASS unless clearly problematic\n- Count words approximately - exact counts are not required\n- If prompt is missing or empty → FAIL\n- If word count is clearly outside specified range (with tolerance) → FAIL\n- If no range specified, only FAIL if word count < 3 or > 10000 (extremely problematic)\n- Apply tolerance to specified ranges (±10% or ±5 words minimum)\n- Be LENIENT - minor deviations should NOT cause FAIL\n- Output PASS if prompt length is reasonable, even if slightly outside strict range",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "a6f6db55-b533-4df4-871b-a9dc03d19d56",
        "source_timestamp": 1769140917000
      },
      "current_quality_dimension_version_id": 5172,
      "reviewer_type": "manual",
      "model": "gpt-5",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This rubric will verify that the prompt word count matches the specified requirement exactly. You perform binary PASS/FAIL evaluation based solely on word count compliance.",
      "code_execution_enabled": null,
      "name": "PROMPT LENGTH COMPLIANCE",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are the Prompt Length Compliance Agent (R2) for Inverse IFEval task validation.\n\nYOUR ROLE:\nYou are a lenient, rule-based evaluator. Your ONLY job is to verify whether the prompt's word count is reasonable. You output BINARY PASS or FAIL only.\n\nYOUR TASK:\nCount the words in the prompt and verify it falls within a reasonable range. Be LENIENT - only fail if the prompt is clearly too short or excessively long. If a specific requirement is specified, check against it with reasonable tolerance.\n\n",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21210,
      "tools": "",
      "sort_order": 2,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 2.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T02:48:49.955632",
      "updated_at": "2026-01-23T04:01:53",
      "id": 391,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 42,
      "quality_dimension_id": 83,
      "prompt": "\nINPUTS:\n- task: The complete task object containing all task components\n- prompt: The user prompt text to be evaluated\n- response_reference: The response reference with criteria array\n- task_type: The task type classification (QC, ITF, CC, CCF, DIA, II, MIM, CA)\n\nGLOBAL RULE - DO NOT INFER:\nAgents must NOT infer, assume, or semantically expand prompt requirements.\nOnly exact textual matches or explicitly stated equivalents in the prompt\nare allowed. If a requirement is not clearly and directly present in the\nprompt text, it MUST be treated as NOT FOUND. Semantic inference, common-sense\nexpansion, or assumed intent is NOT allowed. This rule applies to ALL\nverification steps in this rubric.\n\nEVALUATION CRITERIA:\n\n1. Subjective Data Identification:\n   - Identify any questions or requirements about data that changes over time\n   - Check for questions about current events, current leaders, current rankings\n   - Identify questions about data that is time-dependent\n   - Check for questions without temporal anchors (specific dates/years)\n   - Verify if data would have different answers at different times\n\n2. Objective Data Verification:\n   - Verify that questions about facts include temporal anchors (specific dates/years)\n   - Check that questions reference specific reports, studies, or sources with dates\n   - Ensure questions about rankings reference specific time periods or sources\n   - Verify that historical facts are anchored to specific time periods\n   - Check that data sources are explicitly stated with temporal context\n\n3. Temporal Anchoring Requirements:\n   - Verify that time-dependent questions include explicit temporal anchors\n   - Check that questions specify exact dates, years, or time periods\n   - Ensure questions reference specific reports, studies, or sources with dates\n   - Verify that \"current\" or \"now\" is replaced with specific dates\n   - Check that rankings reference specific time periods or sources\n\n4. Source Specification Requirements:\n   - Verify that questions about rankings or comparisons reference specific sources\n   - Check that questions specify which report, study, or data source is used\n   - Ensure questions include temporal context for sources\n   - Verify that external data references are explicit and time-anchored\n   - Check that questions do not rely on \"general knowledge\" of current state\n\n5. Ambiguous Fact Handling:\n   - Identify facts that appear time-invariant but are commonly debated, ranked,\n     or redefined over time\n   - Examples: \"largest democracy\", \"oldest civilization\", \"fastest growing economy\"\n   - Verify if such facts have explicit source and temporal anchor\n   - If a fact is commonly debated or redefined, treat as SUBJECTIVE unless\n     source and temporal anchor are explicitly provided\n\nSUBJECTIVE DATA PATTERNS (MUST REJECT):\n- Questions about current leaders without temporal anchor:\n  * \"Who is the president of India?\" - SUBJECTIVE (changes over time)\n  * \"Who is the current CEO of Apple?\" - SUBJECTIVE (changes over time)\n  * \"What is the current population of China?\" - SUBJECTIVE (changes over time)\n\n- Questions about current rankings without source or temporal anchor:\n  * \"What are the top 2 airplane companies in the world?\" - SUBJECTIVE\n  * \"Which country has the largest economy?\" - SUBJECTIVE\n  * \"What are the most popular programming languages?\" - SUBJECTIVE\n\n- Questions about current events without temporal anchor:\n  * \"What is happening in the stock market?\" - SUBJECTIVE\n  * \"What are the latest developments in AI?\" - SUBJECTIVE\n  * \"What is the current inflation rate?\" - SUBJECTIVE\n\n- Questions about data that changes frequently:\n  * \"What is the current exchange rate?\" - SUBJECTIVE\n  * \"What are today's stock prices?\" - SUBJECTIVE\n  * \"What is the weather forecast?\" - SUBJECTIVE\n\nOBJECTIVE DATA PATTERNS (ALLOWED):\n- Questions with explicit temporal anchors:\n  * \"Who is the president of India in 2024?\" - OBJECTIVE (fixed point in time)\n  * \"Who was the CEO of Apple in 2023?\" - OBJECTIVE (fixed point in time)\n  * \"What was the population of China in 2020?\" - OBJECTIVE (fixed point in time)\n\n- Questions with specific source references and temporal anchors:\n  * \"What are the top 2 airplane companies based on the 2024 Aviation Industry\n    Report?\" - OBJECTIVE (specific source with date)\n  * \"Which country had the largest economy according to World Bank data in 2023?\"\n    - OBJECTIVE (specific source with date)\n  * \"What were the most popular programming languages according to Stack Overflow\n    Survey 2024?\" - OBJECTIVE (specific source with date)\n\n- Questions about historical facts with temporal anchors:\n  * \"What happened in the stock market on January 15, 2024?\" - OBJECTIVE\n  * \"What were the AI developments announced in Q1 2024?\" - OBJECTIVE\n  * \"What was the inflation rate in the United States in December 2023?\"\n    - OBJECTIVE\n\n- Questions about time-invariant facts:\n  * \"What is the capital of France?\" - OBJECTIVE (does not change)\n  * \"What is the chemical formula for water?\" - OBJECTIVE (does not change)\n  * \"What is the speed of light?\" - OBJECTIVE (does not change)\n  * \"Who wrote Romeo and Juliet?\" - OBJECTIVE (historical fact, does not change)\n\nVERIFICATION PROCESS:\n\nSTEP 1: Extract All Questions and Requirements\n- List all questions asked in the prompt\n- List all requirements stated in the prompt\n- List all evaluation criteria in response_reference\n- Create inventory of all data-checking requirements\n\nSTEP 2: Identify Time-Dependent Data\n- For each question/requirement, determine if it asks about data that changes\n- Check if answer would be different at different times\n- Identify questions without temporal anchors\n- Flag potential subjective data requirements\n\nSTEP 3: Check for Temporal Anchors\n- Verify if time-dependent questions include specific dates/years\n- Check if questions specify exact time periods\n- Verify if questions reference specific reports/studies with dates\n- Flag questions missing temporal anchors\n\nSTEP 4: Check for Source Specifications\n- Verify if ranking/comparison questions reference specific sources\n- Check if questions specify which report, study, or data source\n- Verify if sources include temporal context\n- Flag questions missing source specifications\n\nSTEP 5: Verify Objective vs Subjective Classification\n- Classify each question as objective or subjective\n- Verify objective questions have temporal anchors or are time-invariant\n- Verify subjective questions are flagged for rejection\n- Document classification reasoning\n\nSTEP 6: Check Criteria for Fact-Checking Requirements\n- Review response_reference criteria for fact-checking requirements\n- Verify criteria do not require evaluation of subjective data\n- Check if criteria assume current knowledge of changing data\n- Flag criteria requiring subjective fact-checking\n\nSTEP 7: Cross-Reference Prompt and Criteria\n- Verify criteria align with prompt requirements\n- Check if criteria introduce additional fact-checking requirements\n- Ensure criteria do not expand fact-checking beyond prompt\n- Flag any misalignment\n\nSTEP 8: Verify Time-Invariant Facts and Check for Ambiguous Facts\n- Identify questions about facts that do not change\n- Verify these are truly time-invariant (historical facts, scientific constants)\n- Ensure these are not disguised as current data questions\n- Check for ambiguous facts that appear time-invariant but are commonly debated:\n  * \"largest democracy\", \"oldest civilization\", \"fastest growing economy\"\n  * \"most populous\", \"richest country\", \"best performing\"\n- If a fact is commonly debated, ranked, or redefined over time, treat as\n  SUBJECTIVE unless explicit source and temporal anchor are provided\n- Document time-invariant classifications and ambiguous fact handling\n\nSTEP 9: Check for Implicit Temporal Assumptions\n- Look for questions that implicitly assume \"current\" or \"now\"\n- Check for questions that would have different answers over time\n- Verify if temporal context is explicit or implicit\n- Flag implicit temporal assumptions\n\nSTEP 10: Final Verification\n- Perform final check of all questions and criteria\n- Verify no subjective fact-checking requirements exist\n- Confirm all time-dependent questions have temporal anchors\n- Generate final PASS/FAIL decision\n\nALLOWED PATTERNS:\n- Questions with explicit temporal anchors (specific dates/years)\n- Questions referencing specific reports, studies, or sources with dates\n- Questions about time-invariant facts (historical, scientific constants)\n- Questions about historical events with specific time periods\n- Criteria that evaluate compliance, not factual correctness (for CA, DIA tasks)\n- Questions about data from specific, time-anchored sources\n\nDISALLOWED PATTERNS:\n- Questions about current leaders without temporal anchor\n- Questions about current rankings without source or temporal anchor\n- Questions about current events without temporal anchor\n- Questions about data that changes frequently without temporal anchor\n- Questions using \"current\", \"now\", \"today\" without specific dates\n- Questions about rankings without specific source references\n- Criteria requiring evaluation of subjective, time-dependent data\n- Questions that would have different answers at different times\n- Ambiguous facts (commonly debated/ranked) without source and temporal anchor:\n  * \"largest democracy\", \"oldest civilization\", \"fastest growing economy\"\n\nFAILURE CONDITIONS:\n- FAIL if prompt asks about current leaders/events without temporal anchor\n- FAIL if prompt asks about rankings without source or temporal anchor\n- FAIL if prompt asks about time-dependent data without temporal anchor\n- FAIL if criteria require evaluation of subjective, time-dependent data\n- FAIL if questions use \"current\" or \"now\" without specific dates\n- FAIL if questions would have different answers at different times\n- FAIL if questions lack explicit temporal anchors for time-dependent data\n- FAIL if ambiguous facts (commonly debated/ranked) lack source and temporal anchor\n\nAMBIGUOUS FACT RULE:\nIf a fact appears time-invariant but is commonly debated, ranked, or redefined\nover time (e.g., \"largest democracy\", \"oldest civilization\", \"fastest growing\neconomy\"), it MUST be treated as SUBJECTIVE unless a source and temporal anchor\nare explicitly provided. Do not assume such facts are objective without explicit\nsource and date references.\n\nOUTPUT STRICTNESS RULE:\nThe agent must output ONLY the decision format specified below.\nNo additional commentary, explanations, or suggestions are allowed\noutside the defined fields. Do not add extra text, recommendations, or\nelaborations beyond the required format.\n\nDECISION OUTPUT FORMAT:\nPASS / FAIL\n\nReason Code: R10-[CODE]\nWhere CODE is one of:\n- SUBJECTIVE_LEADER: Question about current leader without temporal anchor\n- SUBJECTIVE_RANKING: Question about ranking without source or temporal anchor\n- SUBJECTIVE_EVENT: Question about current event without temporal anchor\n- SUBJECTIVE_DATA: Question about time-dependent data without temporal anchor\n- MISSING_TEMPORAL_ANCHOR: Time-dependent question missing temporal anchor\n- MISSING_SOURCE: Ranking question missing source specification\n- CRITERIA_SUBJECTIVE: Criteria require evaluation of subjective data\n- IMPLICIT_TEMPORAL: Question uses implicit temporal assumption\n- AMBIGUOUS_FACT: Ambiguous fact (commonly debated/ranked) without source and temporal anchor\n\nJustification: [Short, objective statement]\nExample: \"FAIL - R10-SUBJECTIVE_LEADER: Prompt asks 'Who is the president of\nIndia?' without temporal anchor. Should be 'Who is the president of India in\n2024?' to be objective.\"\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "753e3142-0ed3-4056-b3fd-21c584561f1d",
        "source_timestamp": 1769140913000
      },
      "current_quality_dimension_version_id": 5171,
      "reviewer_type": "manual",
      "model": "gpt-5",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This rubric will verify that prompts and criteria do NOT require evaluation of subjective data that changes over time.",
      "code_execution_enabled": null,
      "name": "NO SUBJECTIVE FACT CHECKING",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are a review assistant.You are the Subjective Fact Checking Agent. Your responsibility is to verify\nthat prompts and criteria do NOT require evaluation of subjective data that\nchanges over time. Only objective, time-invariant facts are allowed. This\nensures that task evaluation remains consistent regardless of when the task is\nevaluated, preventing temporal drift in scoring.",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21209,
      "tools": "",
      "sort_order": 1,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 2.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-20T02:46:21.835583",
      "updated_at": "2026-01-22T14:40:16",
      "id": 390,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 42,
      "quality_dimension_id": 82,
      "prompt": "INPUTS:\n- task: The complete task object containing all task components\n- prompt: The user prompt text to be evaluated\n- domain: The assigned domain classification\n- task_type: The task type classification (QC, ITF, CC, CCF, DIA, II, MIM, CA)\n- metadata: Task metadata including domain and task type assignments\n{conversation}\n\nDOMAIN TAXONOMY (for verification):\n- Media, Arts, Culture: 3-15% distribution\n- Education & Research: 10-20% distribution\n- Business, Finance, Industry: 10-20% distribution\n- Sports, Hobbies & Recreation: 3-15% distribution\n- Science, Tech, & Environment: 10-20% distribution\n- Society, Lifestyle & Community: 3-15% distribution\n- Healthcare & Wellness: 3-15% distribution\n- Government, Law & Public Safety: 3-15% distribution\n- Travel & Transportation: 3-10% distribution\n- Other: 1-5% distribution\n\nTASK TYPE DEFINITIONS:\n1. QC (Question Correction): Questions with logical fallacies or all incorrect\n   options. Models must identify the issue rather than forcing an answer.\n2. ITF (Intentional Textual Flaws): Content requiring specific typos,\n   grammatical errors, or stylistic flaws.\n3. CC (Code Without Comments): Functional code violating coding best practices\n   (no comments, minimal variable names).\n4. CCF (Counter-Conventional Formatting): Content avoiding structured formats\n   (no bullet points, numbered lists, paragraph breaks).\n5. DIA (Deliberately Incorrect Answers): Questions requiring specific ratio of\n   wrong answers while answering others correctly.\n6. II (Instructional Induction): Template problems reformulated to avoid\n   template solutions.\n7. MIM (Mid-Turn Instruction Modification): Instructions with mid-prompt\n   modifications that must be followed.\n8. CA (Counterfactual Answering): Questions requiring use of factually\n   incorrect information from provided text.\n\nEVALUATION CRITERIA:\n1. Grammatical Correctness:\n   - Prompt must be grammatically correct and well-structured\n   - No unintentional spelling or syntax errors\n   - Sentences must be complete and coherent\n   - For QC tasks: intentional flaws in question are acceptable\n\n2. Logical Soundness:\n   - Prompt must make logical sense\n   - Instructions must be internally consistent\n   - For QC tasks: logical flaws must be intentional (part of task design)\n   - For non-QC tasks: no unintentional logical errors\n   - All instructions must be executable\n\n3. Domain Alignment:\n   - Prompt content must match the assigned domain classification\n   - Domain expertise must be appropriate for the content\n   - Content must be recognizable as belonging to the assigned domain\n   - Domain classification must be accurate\n\n4. Counter-Intuitive Constraint Explicitness:\n   - Constraint must be explicitly stated (not implied or inferred)\n   - Constraint must be unambiguous (no room for interpretation)\n   - Constraint must be testable (success/failure can be measured)\n   - Constraint must clearly specify what to violate\n   - Quantify when possible (e.g., \"exactly 3 typos\", \"5 out of 10 incorrect\")\n   - Must emphasize priority over standard practices\n\nALLOWED PATTERNS:\n- Explicit constraint statements: \"exactly X typos\", \"do not add comments\",\n  \"no bullet points\", \"exactly 3 sentences\"\n- Quantified constraints: \"exactly 3 sentences\", \"5 out of 10 questions incorrect\"\n- Clear format restrictions: \"no paragraph breaks\", \"single-letter variable names only\"\n- Domain-appropriate content matching classification\n- Grammatically correct, logically sound instructions\n- Testable, verifiable conditions\n\nDISALLOWED PATTERNS:\n- Vague constraint language: \"write poorly\", \"not perfect\", \"somewhat incorrect\",\n  \"make it bad\"\n- Implied constraints not explicitly stated\n- Domain misalignment (content doesn't match assigned domain)\n- Unintentional grammatical or logical errors (except for QC tasks where flaw is intentional)\n- Ambiguous instructions that could be interpreted multiple ways\n- Constraints that cannot be objectively tested\n- Subjective success criteria\n\nFAILURE CONDITIONS:\n- FAIL if prompt contains unintentional grammatical errors\n- FAIL if prompt is logically flawed (except intentional flaws in QC tasks)\n- FAIL if domain classification does not match prompt content\n- FAIL if counter-intuitive constraint is not explicit\n- FAIL if counter-intuitive constraint is ambiguous or untestable\n- FAIL if constraint is implied but not stated\n- FAIL if constraint uses vague language\n\nDECISION OUTPUT FORMAT:\nPASS / FAIL\n\nReason Code: R1-[CODE]\nWhere CODE is one of:\n- GRAMMAR: Grammatical errors present\n- LOGIC: Logical errors present (unintentional)\n- DOMAIN: Domain misalignment\n- CONSTRAINT_IMPLICIT: Constraint not explicit\n- CONSTRAINT_AMBIGUOUS: Constraint ambiguous\n- CONSTRAINT_UNTESTABLE: Constraint not testable\n\nJustification: [Short, objective statement]\nExample: \"FAIL - R1-CONSTRAINT_IMPLICIT: Counter-intuitive constraint uses vague\nlanguage 'write poorly' instead of explicit specification like 'include exactly\n3 typos'.\"\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.1,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "05249460-e6db-4c7d-9327-f6b199ee7b66",
        "source_timestamp": 1769092816000
      },
      "current_quality_dimension_version_id": 5170,
      "reviewer_type": "manual",
      "model": "gpt-5",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "This rubric will evaluate whether a task's prompt is well-formed, logically sound, properly aligned with its assigned domain, and contains an explicit, unambiguous\ncounter-intuitive constraint. You perform binary PASS/FAIL evaluation only.",
      "code_execution_enabled": null,
      "name": "PROMPT QUALITY AND DOMAIN COMPLIANCE",
      "turn_summarizing_prompt": "Please generate an integrated summary that includes:\n  - A brief summary of the feedback for each section along with the key.\n  - An average score computed from all the individual scores. (1<=score<=5)\n  - A short overall justification.\n\nProvide your answer as a well-formatted summary",
      "star_rating_tooltip": {},
      "system_prompt": "You are the Prompt Quality and Domain Compliance Agent. Your responsibility is\nto evaluate whether a task's prompt is well-formed, logically sound, properly\naligned with its assigned domain, and contains an explicit, unambiguous\ncounter-intuitive constraint. You perform binary PASS/FAIL evaluation only.",
      "image_attach_enabled": null,
      "review_display": {
        "options": [
          {
            "value": "Pass"
          },
          {
            "value": "Fail"
          }
        ],
        "type": "BOOLEAN_CHOICE"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21208,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": {
        "model": "gpt-4o",
        "prompt": "This is the evaluation feedback: {agent_feedback}, score {agent_score}",
        "provider": "openai_api",
        "systemPrompt": "You are a review assistant.",
        "temperature": 0,
        "tools": []
      },
      "negative_review_threshold": 2.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.753479",
      "updated_at": "2026-01-19T19:56:45",
      "id": 389,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 53,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nHow accurate the answer is, how little it makes things up, and how clearly it admits limits.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "4b710e04-7699-438a-8c8f-14679678f643",
        "source_timestamp": 1768852605000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether any content fabricates facts, makes assumptions, or introduces unverifiable or invented claims anywhere in the notebook.",
      "code_execution_enabled": null,
      "name": "Factual Accuracy and Hallucination",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21207,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.738780",
      "updated_at": "2026-01-19T19:56:40",
      "id": 388,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 80,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nWhether all notebook cell tags are spelled correctly, formatted correctly, and appear in the exact required sequential order across all turns and model responses.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "9da86cde-e601-44a7-a978-e4456eacc606",
        "source_timestamp": 1768852600000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether all notebook cell tags are spelled correctly, formatted correctly, and appear in the exact required sequential order across all turns and model responses.",
      "code_execution_enabled": null,
      "name": "Cell Tags - Spelling, Format, and Order",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21206,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.734608",
      "updated_at": "2026-01-19T19:56:37",
      "id": 387,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 81,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nWhether all JSON blocks are syntactically valid and whether turn_metadata correctly encodes all instruction types, labels, arguments, and change tracking, and includes at least 4 IF constraints and atleast 2 llm eval constraints(atleast 1 llm_judge).\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "2807b038-77d0-4fbe-ab5e-6df38a28c9f6",
        "source_timestamp": 1768852597000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether all JSON blocks are syntactically valid and whether turn_metadata correctly encodes all instruction types, labels, arguments, and change tracking, and includes at least 4 IF constraints and atleast 2 llm eval constraints(atleast 1 llm_judge).",
      "code_execution_enabled": null,
      "name": "JSON Correct Formatting and Turn_Metadata Accuracy",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21205,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.713578",
      "updated_at": "2026-01-19T19:56:33",
      "id": 386,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 52,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nDialogues should avoid bizarre, artificial, or unrealistic content.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "e572978c-3134-4405-93c2-a23ab638e734",
        "source_timestamp": 1768852593000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Dialogues should avoid bizarre, artificial, or unrealistic content.",
      "code_execution_enabled": null,
      "name": "Dialogue Realisticness",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21204,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.712784",
      "updated_at": "2026-01-19T19:56:29",
      "id": 385,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 55,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nRemove unnecessary preambles/closures. Correct Markdown/JSON formatting should be applied if relevant.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "6bcf8ba9-10d9-4095-8a4d-8b0d7a8956b1",
        "source_timestamp": 1768852589000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether all formatting bans and cleanup rules are followed across the entire notebook.",
      "code_execution_enabled": null,
      "name": "Formatting and Compliance (No Emoji, No Currency Symbols, No Em-Dash, No LaTeX)",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21203,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.696148",
      "updated_at": "2026-01-19T19:56:18",
      "id": 384,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 79,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nWhether notebook metadata correctly and precisely matches the prompt, task type, domain, use case, categories, and CFBench taxonomy, without loose fits or hidden mismatches.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "e6d0e749-a685-4dc3-b3e6-2c250b7e349d",
        "source_timestamp": 1768852578000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether notebook metadata correctly and precisely matches the prompt, task type, domain, use case, categories, and CFBench taxonomy, without loose fits or hidden mismatches.",
      "code_execution_enabled": null,
      "name": "Metadata Accuracy and Taxonomy Alignment",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": null,
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21202,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.690822",
      "updated_at": "2026-01-19T19:56:13",
      "id": 383,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 54,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nThe human-written \"Assistant\" response must be a perfect example of success.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "62c22e71-9a0a-4172-98af-287be6521955",
        "source_timestamp": 1768852573000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether the human-written golden assistant response is a flawless success case under full CFBench evaluation, serving as a canonical example of perfect instruction following and constraint satisfaction.",
      "code_execution_enabled": null,
      "name": "Golden Response Perfection",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21201,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.686386",
      "updated_at": "2026-01-19T19:56:03",
      "id": 382,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 50,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nEvaluates whether the prompt causes at least three metadata instructions to be broken by at least one output from Qwen or Nemotron, and whether at least one instruction has both a PASS and a FAIL across the four responses.\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "c28d463d-777c-4915-997a-946d957a03cf",
        "source_timestamp": 1768852563000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Evaluates whether the prompt meaningfully breaks metadata instructions across four independent responses from the same model (either all Nemotron or all Qwen3), according to CFBench failure rules. Pass/Fail is measured using checklist items and official validators. Pass/Fail rule: In at least 3 out of 4 responses, PASS must be ≤50 percent (i.e., FAIL ≥50 percent). 4 out of 4 meeting this is ideal, but 3 out of 4 is mandatory; the remaining 1 response may have PASS >50 percent. At least one instruction must show both PASS and FAIL across the 4 responses. Failures must be caused by real instruction conflicts, priority violations, or reasoning breakdowns, not by trivial formatting or cosmetic issues alone.",
      "code_execution_enabled": null,
      "name": "Model Breaking Success",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21198,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.685079",
      "updated_at": "2026-01-19T19:56:09",
      "id": 381,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 51,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nDefinition and labeling of aligned vs misaligned instructions and coverage of conflicts\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "de2368d0-0a53-4b0c-83e1-0127a57c9a74",
        "source_timestamp": 1768852569000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether aligned vs misaligned instructions are correctly labeled and whether conflict cases meaningfully test priority handling across benign and adversarial scenarios.",
      "code_execution_enabled": null,
      "name": "Instruction Alignment and Conflict Coverage",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21200,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.677684",
      "updated_at": "2026-01-19T19:56:06",
      "id": 380,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 49,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nQuality realism and diversity of constraints across the six SysBench categories\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "0c1921ba-c2e5-4036-ba09-2aac94933d7a",
        "source_timestamp": 1768852566000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Whether the system message is internally consistent, contradiction-free, enforceable, aligned with metadata, and suitable for checklist-based CFBench evaluation without hidden contradictions, vague priorities, or unenforceable rules.",
      "code_execution_enabled": null,
      "name": "System Message Correctness",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21199,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    },
    {
      "created_at": "2026-01-19T19:55:55.653291",
      "updated_at": "2026-01-19T19:56:00",
      "id": 379,
      "is_enabled": 1,
      "weight": 1.0,
      "project_id": 47,
      "quality_dimension_id": 48,
      "prompt": "Discuss if the following criteria are met in the conversation:\n\n**Criteria:**\n\nClarity of motivation for studying system message following and how SysBench style evaluation fills a gap\n\n**Discussion Structure:**\n\nDiscuss misalignments in free form. If there are no misalignments, write “No issues detected.”\n\n**Score Constraints:**\n\n- If there are any misalignments, give it a \"2\" or below.\n- Give it a \"5\" if there are no misalignments.\n- Give it a \"4\" only if all misalignments are highly debatable.\n- Give it a \"3\" for other cases.\n",
      "prompt_template": null,
      "reviewer_identity_prompt": null,
      "temperature": 0.0,
      "llm_evaluator": "general_purpose_evaluator",
      "datastream_metadata": {
        "uuid": "6170c493-56f7-4f8f-9f32-4b9dd8f474a2",
        "source_timestamp": 1768852560000
      },
      "current_quality_dimension_version_id": null,
      "reviewer_type": "manual",
      "model": "gpt-4o",
      "input_filters": null,
      "use_latest_quality_dimension_version": 0,
      "provider": "openai_api",
      "web_search_enabled": null,
      "is_turn_level": 0,
      "description": "Clarity of why comprehensive constraints following matters, and why CFBench style data plus evaluation better matches user perception.",
      "code_execution_enabled": null,
      "name": "CFBench Problem Framing and Motivation",
      "turn_summarizing_prompt": null,
      "star_rating_tooltip": {},
      "system_prompt": null,
      "image_attach_enabled": null,
      "review_display": {
        "options": [],
        "type": "STAR_RATING"
      },
      "form_stages": null,
      "audio_attach_enabled": null,
      "ac_agent_id": 21197,
      "tools": "",
      "sort_order": 0,
      "is_sequential": 0,
      "sequential_call_params": null,
      "negative_review_threshold": 0.0,
      "is_optional": 0,
      "type": "general"
    }
  ]
}